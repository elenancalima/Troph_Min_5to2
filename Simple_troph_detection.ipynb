{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1uHuwna9snLSF3tZ7Zu0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elenancalima/Troph_Min_5to2/blob/main/Simple_troph_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpNu2T6m03vf",
        "outputId": "13c43f46-b7ad-40b2-a936-e4ca8d3e80bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", which is not installed.\n",
            "stumpy 1.13.0 requires scipy>=1.10, which is not installed.\n",
            "pymc 5.25.1 requires scipy>=1.4.1, which is not installed.\n",
            "yellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, which is not installed.\n",
            "mlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, which is not installed.\n",
            "shap 0.49.1 requires scipy, which is not installed.\n",
            "libpysal 4.13.0 requires scipy>=1.8, which is not installed.\n",
            "hyperopt 0.2.7 requires scipy, which is not installed.\n",
            "dopamine-rl 4.1.2 requires opencv-python>=3.4.8.29, which is not installed.\n",
            "jaxlib 0.5.3 requires scipy>=1.11.1, which is not installed.\n",
            "matplotlib-venn 1.1.2 requires scipy, which is not installed.\n",
            "jax 0.5.3 requires scipy>=1.11.1, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "plotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\n",
            "albumentations 2.0.8 requires scipy>=1.10.0, which is not installed.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, which is not installed.\n",
            "statsmodels 0.14.5 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "lightgbm 4.6.0 requires scipy, which is not installed.\n",
            "pytensor 2.31.7 requires scipy<2,>=1, which is not installed.\n",
            "mizani 0.13.5 requires scipy>=1.8.0, which is not installed.\n",
            "scs 3.2.9 requires scipy, which is not installed.\n",
            "scikit-learn 1.6.1 requires scipy>=1.6.0, which is not installed.\n",
            "clarabel 0.11.1 requires scipy, which is not installed.\n",
            "pynndescent 0.5.13 requires scipy>=1.0, which is not installed.\n",
            "cuml-cu12 25.6.0 requires scipy>=1.8.0, which is not installed.\n",
            "umap-learn 0.5.9.post2 requires scipy>=1.3.1, which is not installed.\n",
            "xgboost 3.0.5 requires scipy, which is not installed.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "imbalanced-learn 0.14.0 requires scipy<2,>=1.11.4, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "fastai 2.8.4 requires scipy, which is not installed.\n",
            "osqp 1.0.4 requires scipy>=0.13.2, which is not installed.\n",
            "hdbscan 0.8.40 requires scipy>=1.0, which is not installed.\n",
            "treelite 4.4.1 requires scipy, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mOK: numpy 2.0.2 opencv 4.10.0 imageio 2.34.1\n",
            "Smoke test: wrote /content/_smoke.png\n"
          ]
        }
      ],
      "source": [
        "# === Cell 1: minimal, Py3.12-safe, no SciPy/skimage ===\n",
        "!pip -q uninstall -y opencv-python opencv-python-headless numpy scipy scikit-image imageio >/dev/null 2>&1 || true\n",
        "\n",
        "!pip -q install --upgrade --only-binary=:all: \\\n",
        "  numpy==2.0.2 \\\n",
        "  opencv-python-headless==4.10.0.84 \\\n",
        "  imageio==2.34.1\n",
        "\n",
        "import numpy as np, cv2, imageio\n",
        "from imageio import v3 as iio\n",
        "\n",
        "print(\"OK:\",\n",
        "      \"numpy\", np.__version__,\n",
        "      \"opencv\", cv2.__version__,\n",
        "      \"imageio\", imageio.__version__)\n",
        "\n",
        "# tiny smoke test (ensures read/write + resize work)\n",
        "import os\n",
        "arr = np.zeros((10,10), np.uint8)\n",
        "cv2.resize(arr, (5,5))\n",
        "iio.imwrite(\"/content/_smoke.png\", arr)\n",
        "print(\"Smoke test: wrote /content/_smoke.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2 (final): Detector with grayscale front_body_mask + cone brightness + direct 170x170 draw ===\n",
        "import os, glob, math, json, re\n",
        "import numpy as np\n",
        "import cv2\n",
        "from imageio import v3 as iio\n",
        "\n",
        "PARAMS = dict(\n",
        "    scale_factor=5,            # 850 -> 170\n",
        "    min_duration=10,           # frames for stationarity check\n",
        "    iou_stationary_tol=0.10,   # mean IoU >= 1 - tol\n",
        "\n",
        "    # brightness change gating inside abdomen masks (composite red channel)\n",
        "    brightnessThreshold=160,   # R channel threshold (0-255)\n",
        "    brightPropDelta=0.15,      # |Δ| of smoothed red>thr fraction\n",
        "    smoothingWindow=5,\n",
        "\n",
        "    # head-direction via cone brightness on GRAYSCALE front_body_mask\n",
        "    coneAngle_deg=30,\n",
        "    coneLength=60,\n",
        "    rays_per_cone=9,\n",
        "\n",
        "    abdomenToHeadLength=25,\n",
        "    headRadius=10,\n",
        "    min_overlap_pairs=2,\n",
        "    iou_match_threshold=0.30,\n",
        ")\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def ensure_dirs(*ps):\n",
        "    for p in ps: os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def read_rgb(p):\n",
        "    im = iio.imread(p)\n",
        "    if im.ndim != 3 or im.shape[2] != 3:\n",
        "        raise ValueError(f\"expect RGB: {p}\")\n",
        "    return im\n",
        "\n",
        "def to_bgr(img_rgb: np.ndarray) -> np.ndarray:\n",
        "    return np.ascontiguousarray(cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "def read_gray(p):\n",
        "    im = iio.imread(p)\n",
        "    if im.ndim == 2:\n",
        "        g = im\n",
        "    elif im.ndim == 3:\n",
        "        g = cv2.cvtColor(to_bgr(im), cv2.COLOR_BGR2GRAY)  # robust if stored RGB-gray\n",
        "    else:\n",
        "        raise ValueError(f\"expect gray or RGB: {p}\")\n",
        "    if g.dtype != np.uint8:\n",
        "        g = np.clip(g, 0, 255).astype(np.uint8)\n",
        "    return g\n",
        "\n",
        "def read_bin(p):\n",
        "    im = iio.imread(p)\n",
        "    if im.ndim == 3: im = im[...,0]\n",
        "    return (im > 127).astype(np.uint8)\n",
        "\n",
        "def iou(a, b):\n",
        "    inter = np.bitwise_and(a, b).sum()\n",
        "    if inter == 0: return 0.0\n",
        "    union = np.bitwise_or(a, b).sum()\n",
        "    return float(inter) / float(union)\n",
        "\n",
        "def clamp(y, x, H, W):\n",
        "    return max(0, min(H-1, int(round(y)))), max(0, min(W-1, int(round(x))))\n",
        "\n",
        "def find_nearest_boundary(mask01, cy, cx):\n",
        "    cnts, _ = cv2.findContours((mask01*255).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    if not cnts: return cy, cx\n",
        "    best_d2, by, bx = 1e18, cy, cx\n",
        "    for c in cnts:\n",
        "        pts = c.reshape(-1,2)  # (x,y)\n",
        "        dy = pts[:,1]-cy; dx = pts[:,0]-cx\n",
        "        d2 = dx*dx + dy*dy\n",
        "        j = int(np.argmin(d2))\n",
        "        if d2[j] < best_d2:\n",
        "            best_d2 = float(d2[j]); by, bx = int(pts[j,1]), int(pts[j,0])\n",
        "    return by, bx\n",
        "\n",
        "def region_axis_unit(mask01):\n",
        "    m = cv2.moments((mask01*255).astype(np.uint8), binaryImage=True)\n",
        "    if m['m00'] == 0: return (0.0, 1.0)\n",
        "    mu20, mu02, mu11 = m['mu20'], m['mu02'], m['mu11']\n",
        "    cov = np.array([[mu20, mu11],[mu11, mu02]], dtype=np.float64)\n",
        "    w,v = np.linalg.eigh(cov)\n",
        "    vmaj = v[:,1]\n",
        "    n = np.hypot(vmaj[0], vmaj[1]) + 1e-9\n",
        "    vx, vy = vmaj[0]/n, vmaj[1]/n\n",
        "    return (vy, vx)  # (dy, dx)\n",
        "\n",
        "def axis_phi_deg_from_unit(dy, dx):\n",
        "    return math.degrees(math.atan2(dy, dx))  # y-down image\n",
        "\n",
        "def connected_components(mask01):\n",
        "    num, labels, stats, cents = cv2.connectedComponentsWithStats((mask01>0).astype(np.uint8), connectivity=8)\n",
        "    return num, labels, stats, cents\n",
        "\n",
        "def centroid_from_mask(mask01):\n",
        "    m = cv2.moments((mask01*255).astype(np.uint8), binaryImage=True)\n",
        "    if m['m00'] == 0: return None\n",
        "    return (m['m01']/m['m00'], m['m10']/m['m00'])  # (cy,cx)\n",
        "\n",
        "def draw_mask_contours(canvas_bgr, mask01, color, thickness=1):\n",
        "    cnts, _ = cv2.findContours((mask01*255).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(canvas_bgr, cnts, -1, color, thickness)\n",
        "\n",
        "def colorize_labels(labels):\n",
        "    H, W = labels.shape\n",
        "    out = np.zeros((H,W,3), np.uint8)\n",
        "    rng = np.random.default_rng(0)\n",
        "    unique = [u for u in np.unique(labels) if u!=0]\n",
        "    lut = {0:(0,0,0)}\n",
        "    for u in unique:\n",
        "        lut[u] = tuple(int(x) for x in rng.integers(50, 255, size=3))\n",
        "    return out\n",
        "\n",
        "# --- map full-res point to small canvas (draw directly at 170x170) ---\n",
        "def downscale_pt(y, x, H, W, h_small, w_small):\n",
        "    sy = int(y * h_small / H)\n",
        "    sx = int(x * w_small / W)\n",
        "    if sy < 0: sy = 0\n",
        "    if sx < 0: sx = 0\n",
        "    if sy >= h_small: sy = h_small - 1\n",
        "    if sx >= w_small: sx = w_small - 1\n",
        "    return sy, sx\n",
        "\n",
        "# --- filename alignment helpers ---\n",
        "_num_re = re.compile(r'(\\d+)')\n",
        "\n",
        "def index_pngs_by_basename(folder: str):\n",
        "    paths = glob.glob(os.path.join(folder, \"*.png\")) + glob.glob(os.path.join(folder, \"*.PNG\"))\n",
        "    return {os.path.basename(p): p for p in paths}\n",
        "\n",
        "import os, re\n",
        "\n",
        "def natural_key(s: str):\n",
        "    \"\"\"Split a string into digit and non-digit chunks so 'img_2' < 'img_10'.\"\"\"\n",
        "    return [int(t) if t.isdigit() else t.lower() for t in re.findall(r'\\d+|\\D+', s)]\n",
        "\n",
        "def _list_images_sorted(dir_path, exts=(\".png\", \".jpg\", \".jpeg\", \".bmp\")):\n",
        "    \"\"\"List images in a dir and sort by natural (numeric-aware) filename order.\"\"\"\n",
        "    if not os.path.isdir(dir_path):\n",
        "        raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
        "    files = [\n",
        "        os.path.join(dir_path, f)\n",
        "        for f in os.listdir(dir_path)\n",
        "        if os.path.splitext(f)[1].lower() in exts\n",
        "    ]\n",
        "    files.sort(key=lambda p: natural_key(os.path.basename(p)))\n",
        "    return files\n",
        "\n",
        "def align_triplet(vid_dir: str, abd_dir: str, fb_dir: str):\n",
        "    \"\"\"\n",
        "    New behavior:\n",
        "      • Treat each series independently: sort each folder by natural order.\n",
        "      • Lengths may differ: truncate all to the shortest count.\n",
        "      • Basenames for outputs come from the video sequence (after truncation).\n",
        "    Returns:\n",
        "      vid_list, abd_list, fb_list, base_list\n",
        "    \"\"\"\n",
        "    vid_list = _list_images_sorted(vid_dir)\n",
        "    abd_list = _list_images_sorted(abd_dir)\n",
        "    fb_list  = _list_images_sorted(fb_dir)\n",
        "\n",
        "    counts = (len(vid_list), len(abd_list), len(fb_list))\n",
        "    n = min(counts)\n",
        "    if n == 0:\n",
        "        raise FileNotFoundError(\n",
        "            \"No images to align.\\n\"\n",
        "            f\"  input_vid: {len(vid_list)} in {vid_dir}\\n\"\n",
        "            f\"  abdomen_mask: {len(abd_list)} in {abd_dir}\\n\"\n",
        "            f\"  front_body_mask: {len(fb_list)} in {fb_dir}\"\n",
        "        )\n",
        "    if len(set(counts)) != 1:\n",
        "        print(f\"[warn] counts differ (vid, abd, fb) = {counts}. Using first {n} frames of each by sorted order.\")\n",
        "\n",
        "    vid_list = vid_list[:n]\n",
        "    abd_list = abd_list[:n]\n",
        "    fb_list  = fb_list[:n]\n",
        "\n",
        "    # Keep output basenames tied to the video sequence for consistency.\n",
        "    base_list = [os.path.splitext(os.path.basename(p))[0] for p in vid_list]\n",
        "\n",
        "    return vid_list, abd_list, fb_list, base_list\n",
        "\n",
        "# ---- cone brightness scorer on grayscale front_body_mask ----\n",
        "def cone_brightness_score(gray, center_yx, axis_phi_deg, half_deg, length_px, rays):\n",
        "    \"\"\"\n",
        "    Integrates grayscale intensity within a cone fan.\n",
        "    Returns (mean_intensity, rays_lines) for debug drawing.\n",
        "    \"\"\"\n",
        "    H, W = gray.shape\n",
        "    cy, cx = center_yx\n",
        "    total = 0.0\n",
        "    count = 0\n",
        "    rays_lines = []\n",
        "    for a in np.linspace(-half_deg, +half_deg, rays):\n",
        "        ang = math.radians(axis_phi_deg + a)\n",
        "        ux, uy = math.cos(ang), math.sin(ang)  # y-down\n",
        "        seg = []\n",
        "        for r in range(1, length_px+1):\n",
        "            y = int(round(cy + uy*r)); x = int(round(cx + ux*r))\n",
        "            if 0 <= y < H and 0 <= x < W:\n",
        "                seg.append((x, y))\n",
        "                total += float(gray[y, x])\n",
        "                count += 1\n",
        "            else:\n",
        "                break\n",
        "        if seg: rays_lines.append(seg)\n",
        "    mean_intensity = total / (count + 1e-6)\n",
        "    return mean_intensity, rays_lines\n",
        "\n",
        "# ---------- main ----------\n",
        "def process_video_root(video_root, P=PARAMS, debug=False, debug_frame=30):\n",
        "    H=W=850\n",
        "    h_small, w_small = H//P[\"scale_factor\"], W//P[\"scale_factor\"]\n",
        "\n",
        "    vid_dir = os.path.join(video_root, \"input_vid\")\n",
        "    abd_dir = os.path.join(video_root, \"abdomen_mask\")\n",
        "    fb_dir  = os.path.join(video_root, \"front_body_mask\")\n",
        "    out_pt  = os.path.join(video_root, \"simple_troph_point_heatmap\")\n",
        "    out_ln  = os.path.join(video_root, \"simple_participant_line_heatmap\")\n",
        "    ensure_dirs(out_pt, out_ln)\n",
        "\n",
        "    vid_list, abd_list, fb_list, base_list = align_triplet(vid_dir, abd_dir, fb_dir)\n",
        "    n = len(base_list)\n",
        "\n",
        "    dbg_dir = os.path.join(video_root, \"_debug_troph\")\n",
        "    if debug: ensure_dirs(dbg_dir)\n",
        "\n",
        "    next_id = 1\n",
        "    prev_regions = {}  # id -> mask01\n",
        "    tracks = {}        # id -> {'iou_hist': list, 'red_prop_hist': list}\n",
        "\n",
        "    for t in range(n):\n",
        "        comp = read_rgb(vid_list[t])\n",
        "        red  = comp[...,0]                 # for abdomen brightness gating only\n",
        "        abd  = read_bin(abd_list[t])\n",
        "        fb_g = read_gray(fb_list[t])       # grayscale front_body_mask\n",
        "\n",
        "        # 01 inputs overlay (fb visualized via Otsu threshold just for display)\n",
        "        if debug and t==debug_frame:\n",
        "            vis = to_bgr(comp)\n",
        "            draw_mask_contours(vis, abd, (0,255,0), 1)   # green abdomen\n",
        "            if fb_g.std() < 1e-6:\n",
        "                fb_bin = (fb_g > int(fb_g.mean())).astype(np.uint8)\n",
        "            else:\n",
        "                _, fb_bin8 = cv2.threshold(fb_g, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "                fb_bin = (fb_bin8 > 0).astype(np.uint8)\n",
        "            draw_mask_contours(vis, fb_bin, (255,0,0), 1)\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"01_inputs.png\"), vis)\n",
        "\n",
        "        # label abdomens\n",
        "        num, labels, stats, cents = connected_components(abd)\n",
        "        cur = []\n",
        "        for lab in range(1, num):\n",
        "            area = int(stats[lab, cv2.CC_STAT_AREA])\n",
        "            if area < 10: continue\n",
        "            mask_l = (labels==lab).astype(np.uint8)\n",
        "            cy, cx = cents[lab][1], cents[lab][0]\n",
        "            cur.append(dict(mask=mask_l, centroid=(cy, cx)))\n",
        "\n",
        "        if debug and t==debug_frame:\n",
        "            colored = colorize_labels(labels)\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"02_labels.png\"), to_bgr(colored))\n",
        "\n",
        "        # assign to prev by IoU\n",
        "        assignments, used = {}, set()\n",
        "        for i, R in enumerate(cur):\n",
        "            best = (0.0, None)\n",
        "            for tid, pm in prev_regions.items():\n",
        "                if tid in used: continue\n",
        "                s = iou(R[\"mask\"], pm)\n",
        "                if s > best[0]: best = (s, tid)\n",
        "            assignments[i] = best[1] if best[0] >= P[\"iou_match_threshold\"] else None\n",
        "\n",
        "        # update tracks with IoU + red proportion\n",
        "        for i, R in enumerate(cur):\n",
        "            tid = assignments[i]\n",
        "            if tid is None:\n",
        "                tid = next_id; next_id += 1\n",
        "                tracks[tid] = dict(iou_hist=[], red_prop_hist=[])\n",
        "            if tid in prev_regions:\n",
        "                tracks[tid][\"iou_hist\"].append(iou(R[\"mask\"], prev_regions[tid]))\n",
        "            m = R[\"mask\"].astype(bool)\n",
        "            prop = float((red[m] >= P[\"brightnessThreshold\"]).mean()) if m.sum()>0 else 0.0\n",
        "            tracks[tid][\"red_prop_hist\"].append(prop)\n",
        "            R[\"track_id\"] = tid\n",
        "\n",
        "        prev_regions = {R[\"track_id\"]: R[\"mask\"] for R in cur}\n",
        "\n",
        "        # candidate regions (stationary + brightness change)\n",
        "        candidates, cand_dbg = [], []\n",
        "        for R in cur:\n",
        "            tid = R[\"track_id\"]\n",
        "            iou_hist = tracks[tid][\"iou_hist\"]\n",
        "            rp_hist  = tracks[tid][\"red_prop_hist\"]\n",
        "            stationary = (len(iou_hist) >= max(1, P[\"min_duration\"]-1) and\n",
        "                          np.mean(iou_hist[-(P[\"min_duration\"]-1):] or [0.0]) >= (1.0 - P[\"iou_stationary_tol\"]))\n",
        "            changing = False\n",
        "            curm = prevm = None\n",
        "            if len(rp_hist) >= P[\"smoothingWindow\"] + 1:\n",
        "                curm  = float(np.mean(rp_hist[-P[\"smoothingWindow\"]:]))\n",
        "                prevm = float(np.mean(rp_hist[-P[\"smoothingWindow\"]-1:-1]))\n",
        "                changing = abs(curm - prevm) >= P[\"brightPropDelta\"]\n",
        "            if stationary and changing:\n",
        "                candidates.append(R)\n",
        "            cand_dbg.append(dict(\n",
        "                frame=t, tid=tid,\n",
        "                iou_mean=float(np.mean(iou_hist[-(P[\"min_duration\"]-1):] or [0.0])),\n",
        "                rp_cur=curm, rp_prev=prevm,\n",
        "                rp_delta=(None if curm is None or prevm is None else curm-prevm),\n",
        "                stationary=bool(stationary), changing=bool(changing)\n",
        "            ))\n",
        "\n",
        "        if debug and t==debug_frame:\n",
        "            vis = to_bgr(comp)\n",
        "            for R in candidates:\n",
        "                draw_mask_contours(vis, R[\"mask\"], (0,255,255), 2)\n",
        "                cy,cx = map(int, R[\"centroid\"])\n",
        "                cv2.putText(vis, f\"id{R['track_id']}\", (cx+5, cy-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 1, cv2.LINE_AA)\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"03_candidates.png\"), vis)\n",
        "            with open(os.path.join(dbg_dir, \"debug_log.txt\"), \"w\") as f:\n",
        "                for row in cand_dbg: f.write(json.dumps(row)+\"\\n\")\n",
        "\n",
        "        # head points from axis + cone BRIGHTNESS on grayscale fb_g\n",
        "        head_points, per_tid_circle = [], {}\n",
        "        if debug and t==debug_frame:\n",
        "            vis_axes = to_bgr(comp)\n",
        "\n",
        "        for R in candidates:\n",
        "            dy_u, dx_u = region_axis_unit(R[\"mask\"])\n",
        "            phi = axis_phi_deg_from_unit(dy_u, dx_u)\n",
        "            cy, cx = R[\"centroid\"]\n",
        "\n",
        "            Fscore, rays_f = cone_brightness_score(fb_g, (cy, cx), phi,\n",
        "                                                   P[\"coneAngle_deg\"], P[\"coneLength\"], P[\"rays_per_cone\"])\n",
        "            Bscore, rays_b = cone_brightness_score(fb_g, (cy, cx), phi+180.0,\n",
        "                                                   P[\"coneAngle_deg\"], P[\"coneLength\"], P[\"rays_per_cone\"])\n",
        "\n",
        "            ratio = (Fscore - Bscore) / (Fscore + Bscore + 1e-6)  # normalized contrast [-1,1]\n",
        "            sign = +1.0 if ratio >= 0.0 else -1.0\n",
        "\n",
        "            hy = cy + sign * dy_u * P[\"abdomenToHeadLength\"]\n",
        "            hx = cx + sign * dx_u * P[\"abdomenToHeadLength\"]\n",
        "            hy, hx = clamp(hy, hx, H, W)\n",
        "            head_points.append((hy, hx, R[\"track_id\"]))\n",
        "\n",
        "            if debug and t==debug_frame:\n",
        "                p1 = (int(cx - dx_u*35), int(cy - dy_u*35))\n",
        "                p2 = (int(cx + dx_u*35), int(cy + dy_u*35))\n",
        "                cv2.arrowedLine(vis_axes, p1, p2, (255,255,255), 1, tipLength=0.2)\n",
        "                for seg in rays_f:\n",
        "                    for i in range(1,len(seg)): cv2.line(vis_axes, seg[i-1], seg[i], (0,0,255), 1)\n",
        "                for seg in rays_b:\n",
        "                    for i in range(1,len(seg)): cv2.line(vis_axes, seg[i-1], seg[i], (255,255,0), 1)\n",
        "                cv2.putText(vis_axes, f\"F:{Fscore:.1f} B:{Bscore:.1f} r:{ratio:.3f}\",\n",
        "                            (int(cx)+6, int(cy)+14), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,200,255), 1, cv2.LINE_AA)\n",
        "\n",
        "        if debug and t==debug_frame:\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"04_axes_cones.png\"), vis_axes)\n",
        "\n",
        "        # --- outputs: DRAW DIRECTLY ON 170×170 CANVASES ---\n",
        "        small_point = np.zeros((h_small, w_small), np.uint8)\n",
        "        small_line  = np.zeros((h_small, w_small), np.uint8)\n",
        "\n",
        "        # for full-res overlay\n",
        "        if debug and t==debug_frame:\n",
        "            vis_final = to_bgr(comp).copy()\n",
        "\n",
        "        intersections = np.zeros((H, W), np.uint8)\n",
        "        if head_points:\n",
        "            # build head circle overlaps\n",
        "            head_sum = np.zeros((H, W), np.uint16)\n",
        "            for hy, hx, tid in head_points:\n",
        "                m = np.zeros((H, W), np.uint8)\n",
        "                cv2.circle(m, (hx, hy), P[\"headRadius\"], 1, thickness=-1)\n",
        "                per_tid_circle[tid] = m\n",
        "                head_sum += m.astype(np.uint16)\n",
        "            intersections = (head_sum >= P[\"min_overlap_pairs\"]).astype(np.uint8)\n",
        "\n",
        "        if intersections.any():\n",
        "            num_cc, labs = cv2.connectedComponents(intersections, connectivity=8)\n",
        "            for lab in range(1, num_cc):\n",
        "                comp_mask = (labs==lab).astype(np.uint8)\n",
        "                c = centroid_from_mask(comp_mask)\n",
        "                if c is None:\n",
        "                    continue\n",
        "\n",
        "                cy, cx = clamp(c[0], c[1], H, W)\n",
        "\n",
        "                # draw point on SMALL canvas\n",
        "                sy, sx = downscale_pt(cy, cx, H, W, h_small, w_small)\n",
        "                small_point[sy, sx] = 255\n",
        "\n",
        "                # which abdomens participate (full-res overlap test)\n",
        "                tids = [tid for tid,m in per_tid_circle.items() if (comp_mask & (m>0)).any()]\n",
        "                for tid in tids:\n",
        "                    amask = prev_regions.get(tid, None)\n",
        "                    if amask is None:\n",
        "                        continue\n",
        "                    by, bx = find_nearest_boundary(amask, cy, cx)\n",
        "\n",
        "                    # scale both endpoints to SMALL and draw the line there\n",
        "                    sby, sbx = downscale_pt(by, bx, H, W, h_small, w_small)\n",
        "                    cv2.line(small_line, (sx, sy), (sbx, sby), 255, 1)\n",
        "\n",
        "                    if debug and t==debug_frame:\n",
        "                        cv2.circle(vis_final, (cx, cy), 3, (0,255,0), -1)\n",
        "                        cv2.line(vis_final, (cx, cy), (bx, by), (0,255,0), 2)\n",
        "\n",
        "        if debug and t==debug_frame:\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"05_headpoints_circles.png\"), to_bgr(comp))\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"06_outputs_overlay.png\"), vis_final)\n",
        "\n",
        "        # save SMALL images directly (no resizing step)\n",
        "        base = base_list[t] + \".png\" # Add the .png extension here\n",
        "        iio.imwrite(os.path.join(out_pt, base), small_point)\n",
        "        iio.imwrite(os.path.join(out_ln, base), small_line)\n",
        "\n",
        "        if (t+1) % 25 == 0 or t == n-1:\n",
        "            print(f\"[{t+1}/{n}]\")\n",
        "\n",
        "    print(\"Done.\")"
      ],
      "metadata": {
        "id": "2LD5dfqA2FvO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3 (revised): Fake data generator that CLEANS input folders (new names) ===\n",
        "import os, math, shutil\n",
        "import numpy as np, cv2\n",
        "from imageio import v3 as iio\n",
        "\n",
        "def _ellipse_mask(H, W, cx, cy, a, b, angle_deg):\n",
        "    m = np.zeros((H, W), np.uint8)\n",
        "    cv2.ellipse(m, (int(cx), int(cy)), (int(a), int(b)), float(angle_deg), 0, 360, 255, -1)\n",
        "    return m\n",
        "\n",
        "def _triangle_wedge(H, W, cx, cy, axis_deg, dir_sign, length=60, base=30):\n",
        "    ux, uy = math.cos(math.radians(axis_deg)), -math.sin(math.radians(axis_deg))\n",
        "    px, py = cx + dir_sign*ux*length, cy + dir_sign*uy*length\n",
        "    vx, vy = -uy, ux\n",
        "    b = base/2.0\n",
        "    blx, bly = cx - vx*b, cy - vy*b\n",
        "    brx, bry = cx + vx*b, cy + vy*b\n",
        "    poly = np.array([[blx, bly], [brx, bry], [px, py]], dtype=np.float32)\n",
        "    poly[:, 0] = np.clip(np.round(poly[:, 0]), 0, W-1)\n",
        "    poly[:, 1] = np.clip(np.round(poly[:, 1]), 0, H-1)\n",
        "    m = np.zeros((H, W), np.uint8)\n",
        "    cv2.fillConvexPoly(m, poly.astype(np.int32), 255)\n",
        "    return m\n",
        "\n",
        "def _reset_dir(d):\n",
        "    if os.path.isdir(d):\n",
        "        shutil.rmtree(d)\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "def generate_fake_troph_data(\n",
        "    video_root: str,\n",
        "    n_frames: int = 60,\n",
        "    seed: int = 0,\n",
        "    prefix: str = \"frame_\",\n",
        "    start_index: int = 1,\n",
        "    pad: int = 5,\n",
        "):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    H, W = 850, 850\n",
        "\n",
        "    # UPDATED folder names\n",
        "    out_vid = os.path.join(video_root, \"input_vid\")            # was 'composite_frames'\n",
        "    out_abd = os.path.join(video_root, \"abdomen_mask\")\n",
        "    out_fb  = os.path.join(video_root, \"front_body_mask\")      # was 'body_front_mask'\n",
        "\n",
        "    # CLEAN the three input folders, then recreate them\n",
        "    _reset_dir(out_vid)\n",
        "    _reset_dir(out_abd)\n",
        "    _reset_dir(out_fb)\n",
        "\n",
        "    # scene: 5 abdomens (2 stationary facing, 1 stationary quiet, 2 moving)\n",
        "    A = [\n",
        "        dict(cx=375.0, cy=420.0, a=28, b=18, axis_deg=0.0,   dir_sign=+1, kind=\"stationary_feed\"),\n",
        "        dict(cx=435.0, cy=420.0, a=28, b=18, axis_deg=180.0, dir_sign=+1, kind=\"stationary_feed\"),\n",
        "        dict(cx=200.0, cy=220.0, a=26, b=16, axis_deg=45.0,  dir_sign=+1, kind=\"stationary_quiet\"),\n",
        "        dict(cx=620.0, cy=320.0, a=26, b=16, axis_deg=75.0,  dir_sign=+1, kind=\"moving\"),\n",
        "        dict(cx=180.0, cy=600.0, a=30, b=20, axis_deg=135.0, dir_sign=+1, kind=\"moving\"),\n",
        "    ]\n",
        "    vel = {3: (+0.8, +0.5), 4: (+0.6, -0.7)}  # indices into A\n",
        "\n",
        "    noise = rng.random((H, W), dtype=np.float32)\n",
        "    steps = [0.10, 0.32, 0.55, 0.30]  # ensures detectable Δ in red proportion\n",
        "    step_len = max(5, n_frames // len(steps))\n",
        "\n",
        "    for t in range(n_frames):\n",
        "        comp_rgb = np.full((H, W, 3), 235, np.uint8)  # RGB light background\n",
        "        abd_mask_all = np.zeros((H, W), np.uint8)\n",
        "        fb_mask_all  = np.zeros((H, W), np.uint8)\n",
        "        red_hi_all   = np.zeros((H, W), dtype=bool)\n",
        "\n",
        "        k = min(t // step_len, len(steps)-1)\n",
        "        p_feed, p_quiet = steps[k], 0.10\n",
        "\n",
        "        for i, a in enumerate(A):\n",
        "            if a[\"kind\"] == \"moving\":\n",
        "                dx, dy = vel[i]\n",
        "                a[\"cx\"] += dx; a[\"cy\"] += dy\n",
        "                if not (80 < a[\"cx\"] < W-80): vel[i] = (-dx, dy); a[\"cx\"] = np.clip(a[\"cx\"], 80, W-80)\n",
        "                if not (80 < a[\"cy\"] < H-80): vel[i] = (dx, -dy); a[\"cy\"] = np.clip(a[\"cy\"], 80, H-80)\n",
        "\n",
        "            cx, cy = a[\"cx\"], a[\"cy\"]\n",
        "            m_abd = _ellipse_mask(H, W, cx, cy, a[\"a\"], a[\"b\"], a[\"axis_deg\"])\n",
        "            m_fb  = _triangle_wedge(H, W, cx, cy, a[\"axis_deg\"], a[\"dir_sign\"], length=60, base=30)\n",
        "\n",
        "            abd_mask_all |= (m_abd > 0).astype(np.uint8)\n",
        "            fb_mask_all  |= (m_fb  > 0).astype(np.uint8)\n",
        "\n",
        "            p = p_feed if a[\"kind\"] == \"stationary_feed\" else p_quiet\n",
        "            red_hi_all |= (noise < p) & (m_abd > 0)\n",
        "\n",
        "        # Compose RGB: dark body, base red inside abdomen, extra bright-red \"feeding\" pixels\n",
        "        comp_rgb[abd_mask_all > 0] = (60, 60, 60)             # dark body\n",
        "        comp_rgb[..., 0][abd_mask_all > 0] = 120              # base red inside abdomen\n",
        "        comp_rgb[..., 0][red_hi_all] = 220                    # brighter red where \"feeding\"\n",
        "\n",
        "        base = f\"{prefix}{start_index + t:0{pad}d}.png\"\n",
        "        iio.imwrite(os.path.join(out_vid, base), comp_rgb)\n",
        "        iio.imwrite(os.path.join(out_abd, base), (abd_mask_all*255).astype(np.uint8))\n",
        "        iio.imwrite(os.path.join(out_fb,  base), (fb_mask_all*255).astype(np.uint8))\n",
        "\n",
        "        if (t+1) % 20 == 0 or t == n_frames-1:\n",
        "            print(f\"[fake {t+1}/{n_frames}] wrote {base}\")\n",
        "\n",
        "    print(\"Fake data ready:\",\n",
        "          f\"\\n  input_vid:        {len(os.listdir(out_vid))} PNGs\",\n",
        "          f\"\\n  abdomen_mask:     {len(os.listdir(out_abd))} PNGs\",\n",
        "          f\"\\n  front_body_mask:  {len(os.listdir(out_fb))} PNGs\")\n"
      ],
      "metadata": {
        "id": "IXnlC3LY1OGd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_root = \"/content/fake_video_root\"\n",
        "generate_fake_troph_data(video_root, n_frames=60, seed=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbD99Gs1NdmQ",
        "outputId": "bf814435-6b81-41a8-80f4-82740115b918"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fake 20/60] wrote frame_00020.png\n",
            "[fake 40/60] wrote frame_00040.png\n",
            "[fake 60/60] wrote frame_00060.png\n",
            "Fake data ready: \n",
            "  input_vid:        60 PNGs \n",
            "  abdomen_mask:     60 PNGs \n",
            "  front_body_mask:  60 PNGs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PARAMS = dict(\n",
        "    scale_factor=5,            # 850 -> 170\n",
        "    min_duration=3,\n",
        "    iou_stationary_tol=0.10,   # mean IoU >= 1 - tol\n",
        "    brightnessThreshold=160,   # R channel threshold (0-255)\n",
        "    brightPropDelta=0.02,      # abs diff of smoothed red>thr fraction\n",
        "    smoothingWindow=3,\n",
        "    coneAngle_deg=45,\n",
        "    cone_bg_weight=0.05,\n",
        "    coneLength=80,\n",
        "    rays_per_cone=9,\n",
        "    abdomenToHeadLength=45,\n",
        "    headRadius=30,\n",
        "    min_overlap_pairs=2,\n",
        "    iou_match_threshold=0.4,\n",
        ")\n",
        "\n",
        "\n",
        "video_root = \"/content/fake_video_root\"\n",
        "# Run with debug visuals for frame 30\n",
        "process_video_root(video_root, PARAMS, debug=True, debug_frame=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4OMjnOG2T-M",
        "outputId": "1882fcd0-0959-42e2-def3-48e94a77e393"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25/60]\n",
            "[50/60]\n",
            "[60/60]\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6B: Detect video_root + sanity check (run even if you skipped 6A) ===\n",
        "import os, glob\n",
        "from google.colab import drive\n",
        "\n",
        "# --- config (repeat here so this cell is standalone) ---\n",
        "videoName   = \"tmpvidroot3\"\n",
        "GDRIVE_ROOT = \"/content/drive/MyDrive\"  # or '/content/drive/Shared drives/<YourDrive>'\n",
        "\n",
        "# Ensure Drive is mounted (idempotent)\n",
        "drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "dest_dir = os.path.join(GDRIVE_ROOT, f\"MainConnection_VidRoots/{videoName}/\")\n",
        "\n",
        "REQUIRED = [\"input_vid\", \"abdomen_mask\", \"front_body_mask\"]\n",
        "\n",
        "def has_required(root):\n",
        "    return all(os.path.isdir(os.path.join(root, r)) for r in REQUIRED)\n",
        "\n",
        "# Find candidate video_root(s) that contain the required folders\n",
        "candidates = []\n",
        "if has_required(dest_dir):\n",
        "    candidates.append(dest_dir)\n",
        "\n",
        "top_level = [p for p in os.listdir(dest_dir) if os.path.isdir(os.path.join(dest_dir, p))]\n",
        "for name in top_level:\n",
        "    root = os.path.join(dest_dir, name)\n",
        "    if has_required(root):\n",
        "        candidates.append(root)\n",
        "\n",
        "if not candidates:\n",
        "    # one more level deep\n",
        "    for name in top_level:\n",
        "        lvl1 = os.path.join(dest_dir, name)\n",
        "        if not os.path.isdir(lvl1):\n",
        "            continue\n",
        "        for name2 in os.listdir(lvl1):\n",
        "            root = os.path.join(lvl1, name2)\n",
        "            if os.path.isdir(root) and has_required(root):\n",
        "                candidates.append(root)\n",
        "\n",
        "if not candidates:\n",
        "    print(\"❌ Could not find a folder that contains:\", REQUIRED)\n",
        "    print(\"Top-level entries in dest_dir:\", top_level[:20])\n",
        "    raise RuntimeError(\"video_root not found.\")\n",
        "\n",
        "# Choose the shortest path (usually the intended root)\n",
        "video_root = sorted(candidates, key=lambda p: len(p))[0]\n",
        "print(\"✅ video_root detected:\", video_root)\n",
        "\n",
        "def list_bases(folder):\n",
        "    files = glob.glob(os.path.join(folder, \"*.png\")) + glob.glob(os.path.join(folder, \"*.PNG\"))\n",
        "    return sorted([os.path.basename(f) for f in files])\n",
        "\n",
        "vid_b = set(list_bases(os.path.join(video_root, \"input_vid\")))\n",
        "abd_b = set(list_bases(os.path.join(video_root, \"abdomen_mask\")))\n",
        "fb_b  = set(list_bases(os.path.join(video_root, \"front_body_mask\")))\n",
        "common = sorted(list(vid_b & abd_b & fb_b))[:10]\n",
        "\n",
        "print(f\"Frames: input_vid={len(vid_b)}  abdomen={len(abd_b)}  front_body={len(fb_b)}  common={len(vid_b & abd_b & fb_b)}\")\n",
        "print(\"Sample common basenames:\", common)\n",
        "\n",
        "print(\"\\nUse this in the detector cell:\")\n",
        "print(f\"video_root = r\\\"{video_root}\\\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv-OoQrTnr-j",
        "outputId": "be1743e8-8312-4b25-f980-faf366a7632c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ video_root detected: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3/\n",
            "Frames: input_vid=132  abdomen=132  front_body=132  common=0\n",
            "Sample common basenames: []\n",
            "\n",
            "Use this in the detector cell:\n",
            "video_root = r\"/content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3/\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARAMS = dict(\n",
        "    scale_factor=5,            # 850 -> 170\n",
        "    min_duration=4,\n",
        "    iou_stationary_tol=0.60,   # mean IoU >= 1 - tol\n",
        "    brightnessThreshold=30,   # R channel threshold (0-255)\n",
        "    brightPropDelta=0.00,      # abs diff of smoothed red>thr fraction\n",
        "    smoothingWindow=3,\n",
        "    coneAngle_deg=35,\n",
        "    coneLength=80,\n",
        "    rays_per_cone=9,\n",
        "    cone_bg_weight=0.05,       # Add the missing key with a default value\n",
        "    abdomenToHeadLength=50,\n",
        "    headRadius=15,\n",
        "    min_overlap_pairs=2,\n",
        "    iou_match_threshold=0.01,\n",
        ")\n",
        "\n",
        "process_video_root(video_root, PARAMS, debug=True, debug_frame=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW7cYLloNwi2",
        "outputId": "413ee758-bced-458f-af35-1253b1ac9bc9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25/132]\n",
            "[50/132]\n",
            "[75/132]\n",
            "[100/132]\n",
            "[125/132]\n",
            "[132/132]\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 6A only when unzipping is needed"
      ],
      "metadata": {
        "id": "SU51lvYEnuyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6A: Mount Drive + UNZIP (run only if you need to extract) ===\n",
        "import os, zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# --- config ---\n",
        "videoName   = \"FoodLimit2.5D_gR0033_feeding\"\n",
        "GDRIVE_ROOT = \"/content/drive/MyDrive\"  # or '/content/drive/Shared drives/<YourDrive>'\n",
        "ZIP_REL     = f\"MainConnection_VidRoots/{videoName}/{videoName}_tmpvidroot2.zip\"\n",
        "\n",
        "# --- mount ---\n",
        "drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "zip_path = os.path.join(GDRIVE_ROOT, ZIP_REL)\n",
        "dest_dir = os.path.dirname(zip_path)\n",
        "\n",
        "print(f\"Zip path: {zip_path}\")\n",
        "print(f\"Dest dir: {dest_dir}\")\n",
        "\n",
        "if not os.path.isfile(zip_path):\n",
        "    print(\"❌ Zip not found. Listing parent folder:\")\n",
        "    parent = os.path.dirname(zip_path)\n",
        "    if os.path.isdir(parent):\n",
        "        print(\"Contents of\", parent, \"→\", os.listdir(parent)[:20])\n",
        "    else:\n",
        "        print(\"Parent folder does not exist:\", parent)\n",
        "    raise FileNotFoundError(zip_path)\n",
        "\n",
        "def _is_within_directory(directory, target):\n",
        "    directory = os.path.abspath(directory)\n",
        "    target    = os.path.abspath(target)\n",
        "    return os.path.commonpath([directory]) == os.path.commonpath([directory, target])\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    for member in zf.namelist():\n",
        "        target_path = os.path.join(dest_dir, member)\n",
        "        if not _is_within_directory(dest_dir, target_path):\n",
        "            raise RuntimeError(f\"Blocked unsafe path in zip: {member}\")\n",
        "    print(\"Unzipping...\")\n",
        "    zf.extractall(dest_dir)\n",
        "    print(\"Unzip complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "51-V1s-ME1W_",
        "outputId": "e8323204-def5-437f-8853-0dcf474e4949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Zip path: /content/drive/MyDrive/MainConnection_VidRoots/FoodLimit2.5D_gR0033_feeding/FoodLimit2.5D_gR0033_feeding_tmpvidroot2.zip\n",
            "Dest dir: /content/drive/MyDrive/MainConnection_VidRoots/FoodLimit2.5D_gR0033_feeding\n",
            "Unzipping...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1096316720.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Blocked unsafe path in zip: {member}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unzipping...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unzip complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1827\u001b[0;31m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1828\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "padv_pUDN4kl"
      }
    }
  ]
}