{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaPk+IwSOuRyxnGTDD44GX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elenancalima/Troph_Min_5to2/blob/main/Simple_troph_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose:\n",
        "# - Ensure required Python packages (versions) are present.\n",
        "# - If anything is installed/updated, automatically restart the runtime\n",
        "#   so subsequent cells see the fresh libs.\n",
        "\n",
        "import sys, subprocess\n",
        "\n",
        "def _pip_install(spec: str):\n",
        "    print(f\"[env] pip install -U {spec}\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-Uq\", spec])\n",
        "\n",
        "def _pkg_version(mod_name: str):\n",
        "    try:\n",
        "        import importlib\n",
        "        m = importlib.import_module(mod_name)\n",
        "        return getattr(m, \"__version__\", \"unknown\")\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _needs(spec_pkg: str, import_name: str, min_version: str | None) -> bool:\n",
        "    from packaging.version import Version, InvalidVersion\n",
        "    v = _pkg_version(import_name)\n",
        "    if v is None:\n",
        "        return True\n",
        "    if not min_version:\n",
        "        return False\n",
        "    try:\n",
        "        return Version(v) < Version(min_version.lstrip(\">=\"))\n",
        "    except InvalidVersion:\n",
        "        return True\n",
        "\n",
        "# ---- requirements (adjust as needed) ----\n",
        "REQS = [\n",
        "    # (pip package, python import name, minimum version)\n",
        "    (\"opencv-python-headless\", \"cv2\",   \">=4.5.0\"),\n",
        "    (\"imageio\",               \"imageio\",\">=2.28.0\"),\n",
        "    (\"numpy\",                 \"numpy\",  \">=1.21.0\"),\n",
        "]\n",
        "\n",
        "updated = False\n",
        "\n",
        "# Ensure 'packaging' exists for version comparisons\n",
        "try:\n",
        "    import packaging  # noqa\n",
        "except Exception:\n",
        "    _pip_install(\"packaging\")\n",
        "    updated = True\n",
        "\n",
        "for pkg, imp, minv in REQS:\n",
        "    if _needs(pkg, imp, minv):\n",
        "        _pip_install(pkg + (f\"{minv}\" if minv else \"\"))\n",
        "        updated = True\n",
        "\n",
        "# Optional: useful system tool (tar is already present in Colab)\n",
        "# If you want rsync in the future, uncomment:\n",
        "# subprocess.run([\"apt-get\", \"update\", \"-qq\"], check=False)\n",
        "# subprocess.run([\"apt-get\", \"install\", \"-y\", \"rsync\"], check=False)\n",
        "\n",
        "# Auto-restart if anything changed\n",
        "if updated:\n",
        "    print(\"\\n[env] Runtime will restart to load updated packages. Re-run from Cell 0B afterwards.\")\n",
        "    import IPython\n",
        "    IPython.get_ipython().kernel.do_shutdown(True)\n",
        "else:\n",
        "    # Quick version summary\n",
        "    import cv2, imageio, numpy as np\n",
        "    print(f\"[env] OK  | cv2={cv2.__version__} | imageio={imageio.__version__} | numpy={np.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaSF4r7MEnCq",
        "outputId": "731a62fc-ad0a-4a16-be8c-e76ac7dd6a4f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[env] OK  | cv2=4.12.0 | imageio=2.37.0 | numpy=2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 0B — Drive mount + project paths & globals ===\n",
        "# Purpose:\n",
        "# - Mount Google Drive\n",
        "# - Define canonical paths used across the notebook\n",
        "# - Prepare local working dirs and Python import path\n",
        "\n",
        "import os, sys\n",
        "\n",
        "# 1) Mount Google Drive\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "except Exception as e:\n",
        "    print(\"[env] Not in Colab or Drive mount failed:\", e)\n",
        "\n",
        "# 2) Canonical locations\n",
        "DRIVE_ROOT   = \"/content/drive/MyDrive\"\n",
        "LOCAL_STAGE  = \"/content/_localstage\"   # where we stage video roots locally\n",
        "NBMODS_DIR   = \"/content/_nbmods\"       # where the notebook writes its 'modules'\n",
        "ARCHIVE_NAME = \"__inputs_archive__.tar\" # canonical inputs archive name\n",
        "INPUT_DIRS   = (\"input_vid\", \"abdomen_mask\", \"front_body_mask\")\n",
        "\n",
        "# 3) (Edit these paths to your project)\n",
        "#    - TEST_VIDEO_ROOT: a single video root to test\n",
        "#    - BATCH_ROOT: a directory containing many video roots to process\n",
        "TEST_VIDEO_ROOT = f\"{DRIVE_ROOT}/MainConnection_VidRoots/tmpvidroot3\"  # <- edit if needed\n",
        "BATCH_ROOT      = f\"{DRIVE_ROOT}/MainConnection_VidRoots\"              # <- edit if needed\n",
        "\n",
        "# 4) Ensure local working dirs exist\n",
        "os.makedirs(LOCAL_STAGE, exist_ok=True)\n",
        "os.makedirs(NBMODS_DIR,  exist_ok=True)\n",
        "\n",
        "# 5) Python import path for notebook-written modules\n",
        "if NBMODS_DIR not in sys.path:\n",
        "    sys.path.insert(0, NBMODS_DIR)\n",
        "if \"/content\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content\")\n",
        "\n",
        "# 6) Sanity printout\n",
        "print(\"[paths]\")\n",
        "print(\"  DRIVE_ROOT      :\", DRIVE_ROOT)\n",
        "print(\"  TEST_VIDEO_ROOT :\", TEST_VIDEO_ROOT)\n",
        "print(\"  BATCH_ROOT      :\", BATCH_ROOT)\n",
        "print(\"  LOCAL_STAGE     :\", LOCAL_STAGE)\n",
        "print(\"  NBMODS_DIR      :\", NBMODS_DIR)\n",
        "print(\"  INPUT_DIRS      :\", INPUT_DIRS)\n",
        "print(\"  ARCHIVE_NAME    :\", ARCHIVE_NAME)\n",
        "\n",
        "# Optional quick checks (will only warn)\n",
        "for d in (TEST_VIDEO_ROOT, BATCH_ROOT):\n",
        "    if not os.path.exists(d):\n",
        "        print(f\"[warn] Path not found yet: {d}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56bUUcT9ErSw",
        "outputId": "564e25ab-4795-4eec-96d9-a10ef5ab8667"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[paths]\n",
            "  DRIVE_ROOT      : /content/drive/MyDrive\n",
            "  TEST_VIDEO_ROOT : /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3\n",
            "  BATCH_ROOT      : /content/drive/MyDrive/MainConnection_VidRoots\n",
            "  LOCAL_STAGE     : /content/_localstage\n",
            "  NBMODS_DIR      : /content/_nbmods\n",
            "  INPUT_DIRS      : ('input_vid', 'abdomen_mask', 'front_body_mask')\n",
            "  ARCHIVE_NAME    : __inputs_archive__.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 1 — Config (control panel) ===\n",
        "# Use this single cell to control what runs and with which parameters.\n",
        "\n",
        "#@title Run Controls & Field Params\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# ---- Toggles ----\n",
        "RUN_FAKE  = False  #@param {type:\"boolean\"}\n",
        "RUN_TEST  = False   #@param {type:\"boolean\"}\n",
        "RUN_BATCH = True  #@param {type:\"boolean\"}\n",
        "\n",
        "DEBUG        = True  #@param {type:\"boolean\"}\n",
        "DEBUG_FRAME  = 3     #@param {type:\"number\"}\n",
        "\n",
        "COPY_RAW_OUTPUTS = False   # default: only upload <stub>_simp.tar\n",
        "# set True if you also want raw output folders copied to the Drive stub folder\n",
        "\n",
        "\n",
        "# ---- Batch list file (txt; one subfolder per line under BATCH_ROOT) ----\n",
        "BATCH_DIR_LIST = f\"{DRIVE_ROOT}/MainConnection_VidRoots/batch_dir_list.txt\"  #@param {type:\"string\"}\n",
        "\n",
        "# ---- Field-data detector PARAMS ----\n",
        "FIELD_PARAMS = dict(\n",
        "    scale_factor=5,            # 850 -> 170\n",
        "    min_duration=4,\n",
        "    iou_stationary_tol=0.90,   # mean IoU >= 1 - tol\n",
        "    brightnessThreshold=20,    # R channel threshold (0-255)\n",
        "    brightPropDelta=0.00,      # abs diff of smoothed red>thr fraction\n",
        "    smoothingWindow=3,\n",
        "    coneAngle_deg=35,\n",
        "    coneLength=80,\n",
        "    rays_per_cone=9,\n",
        "    cone_bg_weight=0.05,       # background weighting for cone score\n",
        "    abdomenToHeadLength=60,\n",
        "    headRadius=35,\n",
        "    min_overlap_pairs=2,\n",
        "    iou_match_threshold=0.01,\n",
        ")\n",
        "\n",
        "@dataclass\n",
        "class CFG:\n",
        "    # what to run\n",
        "    run_fake: bool\n",
        "    run_test: bool\n",
        "    run_batch: bool\n",
        "    # debug\n",
        "    debug: bool\n",
        "    debug_frame: int\n",
        "    # paths (from Cell 0B)\n",
        "    test_video_root: str\n",
        "    batch_root: str\n",
        "    batch_dir_list: str\n",
        "    # params\n",
        "    params: dict\n",
        "\n",
        "CFG = CFG(\n",
        "    run_fake=RUN_FAKE,\n",
        "    run_test=RUN_TEST,\n",
        "    run_batch=RUN_BATCH,\n",
        "    debug=DEBUG,\n",
        "    debug_frame=int(DEBUG_FRAME),\n",
        "    test_video_root=TEST_VIDEO_ROOT,  # from Cell 0B\n",
        "    batch_root=BATCH_ROOT,            # from Cell 0B\n",
        "    batch_dir_list=BATCH_DIR_LIST,\n",
        "    params=FIELD_PARAMS,\n",
        ")\n",
        "\n",
        "# Short summary\n",
        "print(\"[config]\")\n",
        "print(\"  run_fake        :\", CFG.run_fake)\n",
        "print(\"  run_test        :\", CFG.run_test)\n",
        "print(\"  run_batch       :\", CFG.run_batch)\n",
        "print(\"  debug           :\", CFG.debug, \" (frame:\", CFG.debug_frame, \")\")\n",
        "print(\"  TEST_VIDEO_ROOT :\", CFG.test_video_root)\n",
        "print(\"  BATCH_ROOT      :\", CFG.batch_root)\n",
        "print(\"  BATCH_DIR_LIST  :\", CFG.batch_dir_list)\n",
        "print(\"  params keys     :\", sorted(CFG.params.keys()))\n",
        "\n",
        "# Optional: gentle warning if batch list file missing\n",
        "import os\n",
        "if CFG.run_batch and not os.path.exists(CFG.batch_dir_list):\n",
        "    print(f\"[warn] BATCH_DIR_LIST not found: {CFG.batch_dir_list}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVg2F_qNE_LW",
        "outputId": "f3234f54-2675-4c5b-f9b2-a2ec280fe503"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[config]\n",
            "  run_fake        : False\n",
            "  run_test        : False\n",
            "  run_batch       : True\n",
            "  debug           : True  (frame: 3 )\n",
            "  TEST_VIDEO_ROOT : /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3\n",
            "  BATCH_ROOT      : /content/drive/MyDrive/MainConnection_VidRoots\n",
            "  BATCH_DIR_LIST  : /content/drive/MyDrive/MainConnection_VidRoots/batch_dir_list.txt\n",
            "  params keys     : ['abdomenToHeadLength', 'brightPropDelta', 'brightnessThreshold', 'coneAngle_deg', 'coneLength', 'cone_bg_weight', 'headRadius', 'iou_match_threshold', 'iou_stationary_tol', 'min_duration', 'min_overlap_pairs', 'rays_per_cone', 'scale_factor', 'smoothingWindow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sections:\n",
        "#   A) Imports & small utils\n",
        "#   B) IO helpers\n",
        "#   C) Geometry / CC helpers\n",
        "#   D) Visualization helpers\n",
        "#   E) Listing & alignment\n",
        "#   F) Cone brightness\n",
        "#   G) Detector main: process_video_root(...)\n",
        "\n",
        "# ---------- A) Imports & small utils ----------\n",
        "import os, re, math, json\n",
        "import numpy as np\n",
        "import cv2\n",
        "from imageio import v3 as iio\n",
        "\n",
        "def ensure_dirs(*ps):\n",
        "    for p in ps: os.makedirs(p, exist_ok=True)\n",
        "\n",
        "# ---------- B) IO helpers ----------\n",
        "def read_rgb(p):\n",
        "    im = iio.imread(p)\n",
        "    if im.ndim != 3 or im.shape[2] != 3:\n",
        "        raise ValueError(f\"expect RGB: {p}\")\n",
        "    return im\n",
        "\n",
        "def to_bgr(img_rgb: np.ndarray) -> np.ndarray:\n",
        "    return np.ascontiguousarray(cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "def read_gray(p):\n",
        "    im = iio.imread(p)\n",
        "    if im.ndim == 2:\n",
        "        g = im\n",
        "    elif im.ndim == 3:\n",
        "        g = cv2.cvtColor(to_bgr(im), cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        raise ValueError(f\"expect gray or RGB: {p}\")\n",
        "    if g.dtype != np.uint8:\n",
        "        g = np.clip(g, 0, 255).astype(np.uint8)\n",
        "    return g\n",
        "\n",
        "def read_bin(p):\n",
        "    im = iio.imread(p)\n",
        "    if im.ndim == 3: im = im[...,0]\n",
        "    return (im > 127).astype(np.uint8)\n",
        "\n",
        "# ---------- C) Geometry / CC helpers ----------\n",
        "def iou(a, b):\n",
        "    inter = np.bitwise_and(a, b).sum()\n",
        "    if inter == 0: return 0.0\n",
        "    union = np.bitwise_or(a, b).sum()\n",
        "    return float(inter) / float(union)\n",
        "\n",
        "def clamp(y, x, H, W):\n",
        "    return max(0, min(H-1, int(round(y)))), max(0, min(W-1, int(round(x))))\n",
        "\n",
        "def find_nearest_boundary(mask01, cy, cx):\n",
        "    cnts, _ = cv2.findContours((mask01*255).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    if not cnts: return cy, cx\n",
        "    best_d2, by, bx = 1e18, cy, cx\n",
        "    for c in cnts:\n",
        "        pts = c.reshape(-1,2)\n",
        "        dy = pts[:,1]-cy; dx = pts[:,0]-cx\n",
        "        d2 = dx*dx + dy*dy\n",
        "        j = int(np.argmin(d2))\n",
        "        if d2[j] < best_d2:\n",
        "            best_d2 = float(d2[j]); by, bx = int(pts[j,1]), int(pts[j,0])\n",
        "    return by, bx\n",
        "\n",
        "def region_axis_unit(mask01):\n",
        "    m = cv2.moments((mask01*255).astype(np.uint8), binaryImage=True)\n",
        "    if m['m00'] == 0: return (0.0, 1.0)\n",
        "    mu20, mu02, mu11 = m['mu20'], m['mu02'], m['mu11']\n",
        "    cov = np.array([[mu20, mu11],[mu11, mu02]], dtype=np.float64)\n",
        "    w,v = np.linalg.eigh(cov)\n",
        "    vmaj = v[:,1]\n",
        "    n = np.hypot(vmaj[0], vmaj[1]) + 1e-9\n",
        "    vx, vy = vmaj[0]/n, vmaj[1]/n\n",
        "    return (vy, vx)  # (dy, dx)\n",
        "\n",
        "def axis_phi_deg_from_unit(dy, dx):\n",
        "    return math.degrees(math.atan2(dy, dx))  # y-down image\n",
        "\n",
        "def connected_components(mask01):\n",
        "    num, labels, stats, cents = cv2.connectedComponentsWithStats((mask01>0).astype(np.uint8), connectivity=8)\n",
        "    return num, labels, stats, cents\n",
        "\n",
        "def centroid_from_mask(mask01):\n",
        "    m = cv2.moments((mask01*255).astype(np.uint8), binaryImage=True)\n",
        "    if m['m00'] == 0: return None\n",
        "    return (m['m01']/m['m00'], m['m10']/m['m00'])  # (cy,cx)\n",
        "\n",
        "# ---------- D) Visualization helpers ----------\n",
        "def draw_mask_contours(canvas_bgr, mask01, color, thickness=1):\n",
        "    cnts, _ = cv2.findContours((mask01*255).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(canvas_bgr, cnts, -1, color, thickness)\n",
        "\n",
        "def colorize_labels(labels):\n",
        "    h, w = labels.shape[:2]\n",
        "    n = int(labels.max()) + 1\n",
        "    palette = np.zeros((max(n,1), 3), dtype=np.uint8)\n",
        "    for lab in range(1, n):\n",
        "        hue = int((lab * 37) % 180)  # OpenCV HSV hue 0..179\n",
        "        palette[lab] = cv2.cvtColor(np.uint8([[[hue, 200, 255]]]), cv2.COLOR_HSV2BGR)[0, 0]\n",
        "    return palette[labels]  # BGR uint8\n",
        "\n",
        "# ---------- E) Listing & alignment ----------\n",
        "def natural_key(s: str):\n",
        "    return [int(t) if t.isdigit() else t.lower() for t in re.findall(r'\\d+|\\D+', s)]\n",
        "\n",
        "def _list_images_sorted(dir_path, exts=(\".png\", \".jpg\", \".jpeg\", \".bmp\")):\n",
        "    if not os.path.isdir(dir_path): raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
        "    files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if os.path.splitext(f)[1].lower() in exts]\n",
        "    files.sort(key=lambda p: natural_key(os.path.basename(p)))\n",
        "    return files\n",
        "\n",
        "def align_triplet(vid_dir: str, abd_dir: str, fb_dir: str):\n",
        "    vid_list = _list_images_sorted(vid_dir)\n",
        "    abd_list = _list_images_sorted(abd_dir)\n",
        "    fb_list  = _list_images_sorted(fb_dir)\n",
        "    n = min(len(vid_list), len(abd_list), len(fb_list))\n",
        "    if n == 0:\n",
        "        raise FileNotFoundError(\n",
        "            \"No images to align.\\n\"\n",
        "            f\"  input_vid: {len(vid_list)} in {vid_dir}\\n\"\n",
        "            f\"  abdomen_mask: {len(abd_list)} in {abd_dir}\\n\"\n",
        "            f\"  front_body_mask: {len(fb_list)} in {fb_dir}\"\n",
        "        )\n",
        "    if len({len(vid_list), len(abd_list), len(fb_list)}) != 1:\n",
        "        print(f\"[warn] counts differ (vid, abd, fb) = {(len(vid_list), len(abd_list), len(fb_list))}. Using first {n} frames of each.\")\n",
        "    vid_list, abd_list, fb_list = vid_list[:n], abd_list[:n], fb_list[:n]\n",
        "    base_list = [os.path.splitext(os.path.basename(p))[0] for p in vid_list]\n",
        "    return vid_list, abd_list, fb_list, base_list\n",
        "\n",
        "# ---------- F) Cone brightness ----------\n",
        "def cone_brightness_score(gray, center_yx, axis_phi_deg, half_deg, length_px, rays):\n",
        "    \"\"\"\n",
        "    Integrate grayscale intensity within a cone fan along an axis.\n",
        "    Returns (mean_intensity, rays_lines) for debug drawing.\n",
        "    \"\"\"\n",
        "    H, W = gray.shape\n",
        "    cy, cx = center_yx\n",
        "    total = 0.0; count = 0; rays_lines = []\n",
        "    for a in np.linspace(-half_deg, +half_deg, rays):\n",
        "        ang = math.radians(axis_phi_deg + a)\n",
        "        ux, uy = math.cos(ang), math.sin(ang)  # y-down\n",
        "        seg = []\n",
        "        for r in range(1, length_px+1):\n",
        "            y = int(round(cy + uy*r)); x = int(round(cx + ux*r))\n",
        "            if 0 <= y < H and 0 <= x < W:\n",
        "                seg.append((x, y))\n",
        "                total += float(gray[y, x]); count += 1\n",
        "            else:\n",
        "                break\n",
        "        if seg: rays_lines.append(seg)\n",
        "    mean_intensity = total / (count + 1e-6)\n",
        "    return mean_intensity, rays_lines\n",
        "\n",
        "# ---------- G) Detector main ----------\n",
        "def process_video_root(video_root, P, debug=False, debug_frame=30):\n",
        "    H=W=850\n",
        "    h_small, w_small = H//P[\"scale_factor\"], W//P[\"scale_factor\"]\n",
        "\n",
        "    vid_dir = os.path.join(video_root, \"input_vid\")\n",
        "    abd_dir = os.path.join(video_root, \"abdomen_mask\")\n",
        "    fb_dir  = os.path.join(video_root, \"front_body_mask\")\n",
        "    out_pt  = os.path.join(video_root, \"simple_troph_point_heatmap\")\n",
        "    out_ln  = os.path.join(video_root, \"simple_participant_line_heatmap\")\n",
        "    ensure_dirs(out_pt, out_ln)\n",
        "\n",
        "    vid_list, abd_list, fb_list, base_list = align_triplet(vid_dir, abd_dir, fb_dir)\n",
        "    n = len(base_list)\n",
        "\n",
        "    dbg_dir = os.path.join(video_root, \"_debug_troph\")\n",
        "    if debug: ensure_dirs(dbg_dir)\n",
        "\n",
        "    next_id = 1\n",
        "    prev_regions = {}\n",
        "    tracks = {}\n",
        "\n",
        "    for t in range(n):\n",
        "        comp = read_rgb(vid_list[t])\n",
        "        red  = comp[...,0]\n",
        "        abd  = read_bin(abd_list[t])\n",
        "        fb_g = read_gray(fb_list[t])\n",
        "\n",
        "        # 01 inputs overlay\n",
        "        if debug and t==debug_frame:\n",
        "            vis = to_bgr(comp)\n",
        "            draw_mask_contours(vis, abd, (0,255,0), 1)\n",
        "            if fb_g.std() < 1e-6:\n",
        "                fb_bin = (fb_g > int(fb_g.mean())).astype(np.uint8)\n",
        "            else:\n",
        "                _, fb_bin8 = cv2.threshold(fb_g, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "                fb_bin = (fb_bin8 > 0).astype(np.uint8)\n",
        "            draw_mask_contours(vis, fb_bin, (255,0,0), 1)\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"01_inputs.png\"), vis)\n",
        "\n",
        "        # labels\n",
        "        num, labels, stats, cents = connected_components(abd)\n",
        "        cur = []\n",
        "\n",
        "        if debug and t == debug_frame:\n",
        "            colored_bgr = colorize_labels(labels)\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"02_labels.png\"), colored_bgr)\n",
        "\n",
        "        for lab in range(1, num):\n",
        "            area = int(stats[lab, cv2.CC_STAT_AREA])\n",
        "            if area < 10: continue\n",
        "            mask_l = (labels == lab).astype(np.uint8)\n",
        "            cy, cx = float(cents[lab][1]), float(cents[lab][0])\n",
        "            cur.append(dict(mask=mask_l, centroid=(cy, cx)))\n",
        "\n",
        "        # assign to prev by IoU\n",
        "        assignments, used = {}, set()\n",
        "        for i, R in enumerate(cur):\n",
        "            best = (0.0, None)\n",
        "            for tid, pm in prev_regions.items():\n",
        "                if tid in used: continue\n",
        "                s = iou(R[\"mask\"], pm)\n",
        "                if s > best[0]: best = (s, tid)\n",
        "            assignments[i] = best[1] if best[0] >= P[\"iou_match_threshold\"] else None\n",
        "\n",
        "        # update tracks with IoU + red proportion\n",
        "        for i, R in enumerate(cur):\n",
        "            tid = assignments[i]\n",
        "            if tid is None:\n",
        "                tid = next_id; next_id += 1\n",
        "                tracks[tid] = dict(iou_hist=[], red_prop_hist=[])\n",
        "            if tid in prev_regions:\n",
        "                tracks[tid][\"iou_hist\"].append(iou(R[\"mask\"], prev_regions[tid]))\n",
        "            m = R[\"mask\"].astype(bool)\n",
        "            prop = float((red[m] >= P[\"brightnessThreshold\"]).mean()) if m.sum()>0 else 0.0\n",
        "            tracks[tid][\"red_prop_hist\"].append(prop)\n",
        "            R[\"track_id\"] = tid\n",
        "\n",
        "        prev_regions = {R[\"track_id\"]: R[\"mask\"] for R in cur}\n",
        "\n",
        "        # candidate regions\n",
        "        candidates, cand_dbg = [], []\n",
        "        for R in cur:\n",
        "            tid = R[\"track_id\"]\n",
        "            iou_hist = tracks[tid][\"iou_hist\"]\n",
        "            rp_hist  = tracks[tid][\"red_prop_hist\"]\n",
        "            stationary = (len(iou_hist) >= max(1, P[\"min_duration\"]-1) and\n",
        "                          np.mean(iou_hist[-(P[\"min_duration\"]-1):] or [0.0]) >= (1.0 - P[\"iou_stationary_tol\"]))\n",
        "            changing = False\n",
        "            curm = prevm = None\n",
        "            if len(rp_hist) >= P[\"smoothingWindow\"] + 1:\n",
        "                curm  = float(np.mean(rp_hist[-P[\"smoothingWindow\"]:]))\n",
        "                prevm = float(np.mean(rp_hist[-P[\"smoothingWindow\"]-1:-1]))\n",
        "                changing = abs(curm - prevm) >= P[\"brightPropDelta\"]\n",
        "            if stationary and changing:\n",
        "                candidates.append(R)\n",
        "            cand_dbg.append(dict(\n",
        "                frame=t, tid=tid,\n",
        "                iou_mean=float(np.mean(iou_hist[-(P[\"min_duration\"]-1):] or [0.0])),\n",
        "                rp_cur=curm, rp_prev=prevm,\n",
        "                rp_delta=(None if curm is None or prevm is None else curm-prevm),\n",
        "                stationary=bool(stationary), changing=bool(changing)\n",
        "            ))\n",
        "\n",
        "        if debug and t==debug_frame:\n",
        "            vis = to_bgr(comp)\n",
        "            for R in candidates:\n",
        "                draw_mask_contours(vis, R[\"mask\"], (0,255,255), 2)\n",
        "                cy,cx = map(int, R[\"centroid\"])\n",
        "                cv2.putText(vis, f\"id{R['track_id']}\", (cx+5, cy-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 1, cv2.LINE_AA)\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"03_candidates.png\"), vis)\n",
        "            with open(os.path.join(dbg_dir, \"debug_log.txt\"), \"w\") as f:\n",
        "                for row in cand_dbg: f.write(json.dumps(row)+\"\\n\")\n",
        "\n",
        "        # head points via cone brightness on grayscale fb_g\n",
        "        head_points, per_tid_circle = [], {}\n",
        "        if debug and t==debug_frame:\n",
        "            vis_axes = to_bgr(comp)\n",
        "\n",
        "        for R in candidates:\n",
        "            dy_u, dx_u = region_axis_unit(R[\"mask\"])\n",
        "            phi = axis_phi_deg_from_unit(dy_u, dx_u)\n",
        "            cy, cx = R[\"centroid\"]\n",
        "\n",
        "            Fscore, rays_f = cone_brightness_score(fb_g, (cy, cx), phi,\n",
        "                                                   P[\"coneAngle_deg\"], P[\"coneLength\"], P[\"rays_per_cone\"])\n",
        "            Bscore, rays_b = cone_brightness_score(fb_g, (cy, cx), phi+180.0,\n",
        "                                                   P[\"coneAngle_deg\"], P[\"coneLength\"], P[\"rays_per_cone\"])\n",
        "\n",
        "            ratio = (Fscore - Bscore) / (Fscore + Bscore + 1e-6)\n",
        "            sign = +1.0 if ratio >= 0.0 else -1.0\n",
        "\n",
        "            hy = cy + sign * dy_u * P[\"abdomenToHeadLength\"]\n",
        "            hx = cx + sign * dx_u * P[\"abdomenToHeadLength\"]\n",
        "            hy, hx = clamp(hy, hx, H, W)\n",
        "            head_points.append((hy, hx, R[\"track_id\"]))\n",
        "\n",
        "            if debug and t==debug_frame:\n",
        "                p1 = (int(cx - dx_u*35), int(cy - dy_u*35))\n",
        "                p2 = (int(cx + dx_u*35), int(cy + dy_u*35))\n",
        "                cv2.arrowedLine(vis_axes, p1, p2, (255,255,255), 1, tipLength=0.2)\n",
        "                for seg in rays_f:\n",
        "                    for i in range(1,len(seg)): cv2.line(vis_axes, seg[i-1], seg[i], (0,0,255), 1)\n",
        "                for seg in rays_b:\n",
        "                    for i in range(1,len(seg)): cv2.line(vis_axes, seg[i-1], seg[i], (255,255,0), 1)\n",
        "                cv2.putText(vis_axes, f\"F:{Fscore:.1f} B:{Bscore:.1f} r:{ratio:.3f}\",\n",
        "                            (int(cx)+6, int(cy)+14), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,200,255), 1, cv2.LINE_AA)\n",
        "\n",
        "        if debug and t==debug_frame:\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"04_axes_cones.png\"), vis_axes)\n",
        "\n",
        "        # --- outputs: draw directly on 170×170 canvases ---\n",
        "        small_point = np.zeros((h_small, w_small), np.uint8)\n",
        "        small_line  = np.zeros((h_small, w_small), np.uint8)\n",
        "\n",
        "        if debug and t==debug_frame:\n",
        "            vis_final = to_bgr(comp).copy()\n",
        "\n",
        "        intersections = np.zeros((H, W), np.uint8)\n",
        "        if head_points:\n",
        "            head_sum = np.zeros((H, W), np.uint16)\n",
        "            for hy, hx, tid in head_points:\n",
        "                m = np.zeros((H, W), np.uint8)\n",
        "                cv2.circle(m, (hx, hy), P[\"headRadius\"], 1, thickness=-1)\n",
        "                per_tid_circle[tid] = m\n",
        "                head_sum += m.astype(np.uint16)\n",
        "            intersections = (head_sum >= P[\"min_overlap_pairs\"]).astype(np.uint8)\n",
        "\n",
        "        # 05: headpoint circles & intersections\n",
        "        if debug and t==debug_frame:\n",
        "            vis_hp = to_bgr(comp).copy()\n",
        "            for tid, m in per_tid_circle.items():\n",
        "                cnts, _ = cv2.findContours((m*255), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                cv2.drawContours(vis_hp, cnts, -1, (0,255,255), 1)\n",
        "            if intersections.any():\n",
        "                cnts, _ = cv2.findContours((intersections*255), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                cv2.drawContours(vis_hp, cnts, -1, (255,0,255), 2)\n",
        "                num_cc, labs = cv2.connectedComponents(intersections, connectivity=8)\n",
        "                for lab in range(1, num_cc):\n",
        "                    c = centroid_from_mask((labs==lab).astype(np.uint8))\n",
        "                    if c is not None:\n",
        "                        cy, cx = int(round(c[0])), int(round(c[1]))\n",
        "                        cv2.circle(vis_hp, (cx, cy), 3, (255,0,255), -1)\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"05_headpoints_circles.png\"), vis_hp)\n",
        "\n",
        "        if intersections.any():\n",
        "            num_cc, labs = cv2.connectedComponents(intersections, connectivity=8)\n",
        "            for lab in range(1, num_cc):\n",
        "                comp_mask = (labs==lab).astype(np.uint8)\n",
        "                c = centroid_from_mask(comp_mask)\n",
        "                if c is None: continue\n",
        "                cy, cx = clamp(c[0], c[1], H, W)\n",
        "                sy, sx = int(cy * h_small / H), int(cx * w_small / W)\n",
        "                sy = min(max(sy, 0), h_small-1)\n",
        "                sx = min(max(sx, 0), w_small-1)\n",
        "                small_point[sy, sx] = 255\n",
        "\n",
        "                tids = [tid for tid,m in per_tid_circle.items() if (comp_mask & (m>0)).any()]\n",
        "                for tid in tids:\n",
        "                    amask = prev_regions.get(tid, None)\n",
        "                    if amask is None: continue\n",
        "                    by, bx = find_nearest_boundary(amask, cy, cx)\n",
        "                    sby, sbx = int(by * h_small / H), int(bx * w_small / W)\n",
        "                    sby = min(max(sby, 0), h_small-1)\n",
        "                    sbx = min(max(sbx, 0), w_small-1)\n",
        "                    #cv2.line(small_line, (sx, sy), (sbx, sby), 255, 1)\n",
        "                    small_line[sbx, sby] = 255\n",
        "\n",
        "                    if debug and t==debug_frame:\n",
        "                        cv2.circle(vis_final, (cx, cy), 3, (0,255,0), -1)\n",
        "                        cv2.line(vis_final, (cx, cy), (bx, by), (0,255,0), 2)\n",
        "\n",
        "        if debug and t==debug_frame:\n",
        "            cv2.imwrite(os.path.join(dbg_dir, \"06_outputs_overlay.png\"), vis_final)\n",
        "\n",
        "        # save SMALL images directly (no resizing step)\n",
        "        base = base_list[t] + \".png\"\n",
        "        iio.imwrite(os.path.join(out_pt, base), small_point)\n",
        "        iio.imwrite(os.path.join(out_ln, base), small_line)\n",
        "\n",
        "        if (t+1) % 25 == 0 or t == n-1:\n",
        "            print(f\"[{t+1}/{n}]\")\n",
        "\n",
        "    print(\"Done.\")\n"
      ],
      "metadata": {
        "id": "saUUutB4HBsG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2B: Staging"
      ],
      "metadata": {
        "id": "C8rwrp2d77ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2B — Staging (TAR-only, export *_simp.tar; optional raw copy) ===\n",
        "# Assumptions:\n",
        "#   • You provide a pre-made TAR on Drive: <stub>.tar (Windows \"Send to → Compressed (zipped) → .tar\").\n",
        "#   • The TAR has a single wrapper folder containing: input_vid/, abdomen_mask/, front_body_mask/\n",
        "#   • We NEVER build input archives in Colab; we only consume <stub>.tar.\n",
        "# Behavior:\n",
        "#   • Process locally for speed.\n",
        "#   • DEFAULT: package entire local result as <stub>_simp.tar and upload it next to <stub>.tar.\n",
        "#   • OPTIONAL: also copy raw output folders back to the Drive stub folder when COPY_RAW_OUTPUTS=True in Config.\n",
        "#\n",
        "# Required upstream:\n",
        "#   • process_video_root(...) defined in Cell 2A.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Constants\n",
        "LOCAL_STAGE = \"/content/_localstage\"\n",
        "INPUT_DIRS  = (\"input_vid\", \"abdomen_mask\", \"front_body_mask\")\n",
        "# Output subfolders our detector produces (extend if you add more)\n",
        "OUTPUT_DIRS = (\"simple_troph_point_heatmap\", \"simple_participant_line_heatmap\", \"_debug_troph\")\n",
        "\n",
        "# --- small helpers ---\n",
        "def _ensure_dir(p: str):\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def _run(cmd, cwd=None, label=None, tolerate_patterns=None):\n",
        "    \"\"\"Run a command; on failure, show combined stdout/stderr (tail).\"\"\"\n",
        "    import shlex\n",
        "    p = subprocess.run(\n",
        "        cmd,\n",
        "        cwd=cwd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "    )\n",
        "    out = p.stdout or \"\"\n",
        "    if p.returncode != 0:\n",
        "        if tolerate_patterns and any(pat in out for pat in tolerate_patterns):\n",
        "            print(f\"[warn] tolerated nonzero exit for {label or cmd[0]} (rc={p.returncode})\")\n",
        "            print(out.rstrip()[-800:])\n",
        "            return out\n",
        "        tail = out[-2000:]\n",
        "        raise RuntimeError(\n",
        "            f\"Command failed (rc={p.returncode}) [{label or cmd[0]}]\\n\"\n",
        "            f\"$ {shlex.join(cmd)}\\n\"\n",
        "            f\"--- stdout/stderr (tail) ---\\n{tail}\"\n",
        "        )\n",
        "    return out\n",
        "\n",
        "def _tar_extract(tar_path: str, dest_dir: str):\n",
        "    _ensure_dir(dest_dir)\n",
        "    _run([\"tar\", \"-xf\", tar_path, \"-C\", dest_dir], label=\"tar-extract\")\n",
        "\n",
        "def _tar_create_dir(parent_dir: str, folder_name: str, out_tar_path: str):\n",
        "    \"\"\"Create a tar that contains `folder_name/` as the top-level entry.\"\"\"\n",
        "    _ensure_dir(os.path.dirname(out_tar_path))\n",
        "    _run([\"tar\", \"-cf\", out_tar_path, folder_name], cwd=parent_dir, label=\"tar-create\")\n",
        "\n",
        "def _copy_dir_subset(src_root: str, dst_root: str, exclude_names):\n",
        "    \"\"\"Copy everything from src_root to dst_root except names in exclude_names.\"\"\"\n",
        "    _ensure_dir(dst_root)\n",
        "    exclude = set(exclude_names)\n",
        "    for name in os.listdir(src_root):\n",
        "        if name in exclude:\n",
        "            continue\n",
        "        sp = os.path.join(src_root, name)\n",
        "        dp = os.path.join(dst_root, name)\n",
        "        if os.path.isdir(sp):\n",
        "            if os.path.exists(dp):\n",
        "                shutil.rmtree(dp, ignore_errors=True)\n",
        "            shutil.copytree(sp, dp)\n",
        "        else:\n",
        "            shutil.copy2(sp, dp)\n",
        "\n",
        "def _canonicalize_inputs_root(root: str):\n",
        "    \"\"\"\n",
        "    After extraction, ensure `root` has input_vid/, abdomen_mask/, front_body_mask/ directly under it.\n",
        "    If there's exactly one wrapper directory, move *all* of its contents up (not just the inputs).\n",
        "    \"\"\"\n",
        "    # Already canonical?\n",
        "    if all(os.path.isdir(os.path.join(root, d)) for d in INPUT_DIRS):\n",
        "        return\n",
        "\n",
        "    # Find single wrapper\n",
        "    entries = [e for e in os.listdir(root) if os.path.isdir(os.path.join(root, e))]\n",
        "    if len(entries) != 1:\n",
        "        raise FileNotFoundError(f\"Expected a single wrapper folder inside {root}, found: {entries}\")\n",
        "\n",
        "    wrapper = os.path.join(root, entries[0])\n",
        "    # Validate inputs exist inside wrapper (to avoid promoting wrong folder)\n",
        "    if not all(os.path.isdir(os.path.join(wrapper, d)) for d in INPUT_DIRS):\n",
        "        raise FileNotFoundError(f\"Wrapper {wrapper} does not contain required {INPUT_DIRS}\")\n",
        "\n",
        "    # Move EVERYTHING (files + folders) from wrapper/* up to root/*\n",
        "    for name in os.listdir(wrapper):\n",
        "        src = os.path.join(wrapper, name)\n",
        "        dst = os.path.join(root, name)\n",
        "        # No conflicts expected (root only holds the wrapper), but be safe:\n",
        "        if os.path.exists(dst):\n",
        "            # If conflict, remove destination then move\n",
        "            if os.path.isdir(dst):\n",
        "                shutil.rmtree(dst, ignore_errors=True)\n",
        "            else:\n",
        "                os.remove(dst)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "    # Remove now-empty wrapper\n",
        "    shutil.rmtree(wrapper, ignore_errors=True)\n",
        "\n",
        "\n",
        "def _print_inputs_sanity(root: str, max_show=2):\n",
        "    \"\"\"Optional: quick counts and a couple of sample names per input dir.\"\"\"\n",
        "    import glob\n",
        "    for d in INPUT_DIRS:\n",
        "        folder = os.path.join(root, d)\n",
        "        files = sorted(glob.glob(os.path.join(folder, \"*.png\")) + glob.glob(os.path.join(folder, \"*.PNG\")))\n",
        "        n = len(files)\n",
        "        head = [os.path.basename(x) for x in files[:max_show]]\n",
        "        tail = [os.path.basename(x) for x in files[-max_show:]] if n > max_show else []\n",
        "        print(f\"[sanity] {d}: {n} PNGs\", f\"head={head}\" if head else \"\", f\"tail={tail}\" if tail else \"\")\n",
        "\n",
        "def _count_min_frames(root: str) -> int:\n",
        "    \"\"\"Minimum frame count across the three input dirs.\"\"\"\n",
        "    import glob\n",
        "    def _cnt(sub):\n",
        "        p = os.path.join(root, sub)\n",
        "        return len(glob.glob(os.path.join(p, \"*.png\")) + glob.glob(os.path.join(p, \"*.PNG\")))\n",
        "    return min(_cnt(\"input_vid\"), _cnt(\"abdomen_mask\"), _cnt(\"front_body_mask\"))\n",
        "\n",
        "# --- main wrapper (TAR-only; exports *_simp.tar; optional raw copy) ---\n",
        "def process_video_root_localfirst(\n",
        "    drive_video_root: str,\n",
        "    P: dict,\n",
        "    debug: bool = False,\n",
        "    debug_frame: int | None = None,\n",
        "    keep_local: bool = False,\n",
        "    copy_raw_outputs: bool = None,   # None → read from global COPY_RAW_OUTPUTS (default False)\n",
        "):\n",
        "    \"\"\"\n",
        "    Consume pre-supplied <stub>.tar by appending '.tar' to `drive_video_root`.\n",
        "    Process locally, then:\n",
        "      • ALWAYS create <stub>_simp.tar from the local result and place it next to <stub>.tar on Drive.\n",
        "      • OPTIONALLY also copy raw outputs back to the Drive stub folder when copy_raw_outputs=True.\n",
        "    \"\"\"\n",
        "    # resolve optional flag from Config if not provided\n",
        "    if copy_raw_outputs is None:\n",
        "        copy_raw_outputs = bool(globals().get(\"COPY_RAW_OUTPUTS\", False))\n",
        "\n",
        "    base      = os.path.basename(os.path.normpath(drive_video_root))     # e.g., \"tmpvidroot3\"\n",
        "    drive_tar = drive_video_root.rstrip(\"/\\\\\") + \".tar\"                  # …/tmpvidroot3.tar\n",
        "    if not os.path.exists(drive_tar):\n",
        "        raise FileNotFoundError(f\"Archive not found: {drive_tar}\")\n",
        "\n",
        "    local_root      = os.path.join(LOCAL_STAGE, base)                     # /content/_localstage/tmpvidroot3\n",
        "    temp_tar_local  = os.path.join(LOCAL_STAGE, f\"{base}__inputs.tar\")\n",
        "    result_tar_local = os.path.join(LOCAL_STAGE, f\"{base}_simp.tar\")      # local packaged result\n",
        "    out_tar_drive    = os.path.join(os.path.dirname(drive_tar), f\"{base}_simp.tar\")\n",
        "\n",
        "    # fresh local workspace\n",
        "    if os.path.isdir(local_root):\n",
        "        shutil.rmtree(local_root, ignore_errors=True)\n",
        "    _ensure_dir(LOCAL_STAGE)\n",
        "    _ensure_dir(local_root)\n",
        "\n",
        "    # stage-in: copy one big file, extract, canonicalize\n",
        "    t0 = time.time()\n",
        "    print(f\"[stage] Using TAR -> local: {drive_tar} -> {local_root}\")\n",
        "    shutil.copy2(drive_tar, temp_tar_local)\n",
        "    _tar_extract(temp_tar_local, local_root)\n",
        "    os.remove(temp_tar_local)\n",
        "    _canonicalize_inputs_root(local_root)\n",
        "    _print_inputs_sanity(local_root, max_show=2)\n",
        "    print(f\"[stage] Stage-in done in {time.time()-t0:.1f}s\")\n",
        "\n",
        "    # clamp debug_frame so we always hit a valid frame if debug=True\n",
        "    if debug and debug_frame is not None:\n",
        "        n = _count_min_frames(local_root)\n",
        "        if n <= 0:\n",
        "            df = 0\n",
        "        elif debug_frame < 0:\n",
        "            df = n - 1\n",
        "        elif debug_frame >= n:\n",
        "            df = n - 1\n",
        "        else:\n",
        "            df = debug_frame\n",
        "        print(f\"[stage] Using debug_frame={df} (clamped)\")\n",
        "    else:\n",
        "        df = debug_frame\n",
        "        print(\"[stage] Debug disabled\")\n",
        "\n",
        "    # run locally\n",
        "    t1 = time.time()\n",
        "    print(\"[run] process_video_root(...) on local copy\")\n",
        "    result = process_video_root(local_root, P, debug=debug, debug_frame=df)\n",
        "    print(f\"[run] done in {time.time()-t1:.1f}s\")\n",
        "\n",
        "    # PACKAGE RESULT: tar the entire local video root (inputs + outputs)\n",
        "    t2 = time.time()\n",
        "    print(f\"[export] Packaging result to: {result_tar_local}\")\n",
        "    _tar_create_dir(parent_dir=os.path.dirname(local_root), folder_name=os.path.basename(local_root), out_tar_path=result_tar_local)\n",
        "    print(f\"[export] Uploading packaged tar to Drive: {out_tar_drive}\")\n",
        "    shutil.copy2(result_tar_local, out_tar_drive)\n",
        "    os.remove(result_tar_local)\n",
        "    print(f\"[export] Packaging + upload done in {time.time()-t2:.1f}s\")\n",
        "\n",
        "    # OPTIONAL: also copy raw outputs back to Drive folder\n",
        "    if copy_raw_outputs:\n",
        "        t3 = time.time()\n",
        "        out_dest = drive_video_root  # ensure folder exists\n",
        "        _ensure_dir(out_dest)\n",
        "        print(\"[stage] Copying raw outputs back to Drive stub folder (inputs skipped)\")\n",
        "        _copy_dir_subset(local_root, out_dest, exclude_names=INPUT_DIRS)\n",
        "        print(f\"[stage] Copy-back done in {time.time()-t3:.1f}s\")\n",
        "        # confirm debug folder presence\n",
        "        if debug:\n",
        "            dbg = os.path.join(out_dest, \"_debug_troph\")\n",
        "            if os.path.isdir(dbg):\n",
        "                import glob\n",
        "                n_dbg = len(glob.glob(os.path.join(dbg, \"*.png\")))\n",
        "                print(f\"[stage] Debug folder present: {dbg}  ({n_dbg} PNGs)\")\n",
        "            else:\n",
        "                print(\"[stage] Note: no _debug_troph folder on Drive (images only written when t == debug_frame).\")\n",
        "    else:\n",
        "        print(\"[stage] Skipping raw output copy (COPY_RAW_OUTPUTS=False).\")\n",
        "\n",
        "    # cleanup local\n",
        "    if keep_local:\n",
        "        print(f\"[stage] Keeping local: {local_root}\")\n",
        "    else:\n",
        "        shutil.rmtree(local_root, ignore_errors=True)\n",
        "        print(\"[stage] Local staging cleaned\")\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "2ElhtXL2KoIC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2C — Fake data suite (definitions only; matches original behavior) ===\n",
        "# Folders expected by the detector:\n",
        "#   input_vid/ (RGB), abdomen_mask/ (binary 0/255), front_body_mask/ (binary 0/255)\n",
        "# Default local root for fake data:\n",
        "FAKE_VIDEO_ROOT = \"/content/fake_video_root\"\n",
        "\n",
        "import os, math, shutil\n",
        "import numpy as np, cv2\n",
        "from imageio import v3 as iio\n",
        "\n",
        "# -- helpers -------------------------------------------------\n",
        "def _ellipse_mask(H: int, W: int, cx: float, cy: float, a: float, b: float, angle_deg: float) -> np.ndarray:\n",
        "    \"\"\"Filled ellipse mask (uint8 0/255). Note: cv2.ellipse uses (x, y) order for center and axes.\"\"\"\n",
        "    m = np.zeros((H, W), np.uint8)\n",
        "    cv2.ellipse(m, (int(cx), int(cy)), (int(a), int(b)), float(angle_deg), 0, 360, 255, -1)\n",
        "    return m\n",
        "\n",
        "def _triangle_wedge(H: int, W: int, cx: float, cy: float, axis_deg: float, dir_sign: int, length: int = 60, base: int = 30) -> np.ndarray:\n",
        "    \"\"\"Isosceles triangular wedge pointing along +/− axis; returns uint8 mask 0/255.\"\"\"\n",
        "    # axis_deg: 0° points right; positive angles rotate counterclockwise in image coords\n",
        "    ux, uy = math.cos(math.radians(axis_deg)), -math.sin(math.radians(axis_deg))\n",
        "    px, py = cx + dir_sign * ux * length, cy + dir_sign * uy * length\n",
        "    vx, vy = -uy, ux\n",
        "    b = base / 2.0\n",
        "    blx, bly = cx - vx * b, cy - vy * b\n",
        "    brx, bry = cx + vx * b, cy + vy * b\n",
        "    poly = np.array([[blx, bly], [brx, bry], [px, py]], dtype=np.float32)\n",
        "    poly[:, 0] = np.clip(np.round(poly[:, 0]), 0, W - 1)\n",
        "    poly[:, 1] = np.clip(np.round(poly[:, 1]), 0, H - 1)\n",
        "    m = np.zeros((H, W), np.uint8)\n",
        "    cv2.fillConvexPoly(m, poly.astype(np.int32), 255)\n",
        "    return m\n",
        "\n",
        "def _reset_dir(d: str) -> None:\n",
        "    \"\"\"Delete and recreate a directory.\"\"\"\n",
        "    if os.path.isdir(d):\n",
        "        shutil.rmtree(d)\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# -- main generator ------------------------------------------\n",
        "def generate_fake_troph_data(\n",
        "    video_root: str,\n",
        "    n_frames: int = 60,\n",
        "    seed: int = 0,\n",
        "    prefix: str = \"frame_\",\n",
        "    start_index: int = 1,\n",
        "    pad: int = 5,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Synthesize a video_root with the exact structure your detector expects:\n",
        "      • input_vid/         (RGB 850×850)     — RED channel modulated over time\n",
        "      • abdomen_mask/      (binary 0/255)    — multiple ellipses (some moving)\n",
        "      • front_body_mask/   (binary 0/255)    — triangular 'forward' wedges\n",
        "    Prints periodic progress identical to your previous behavior.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    H, W = 850, 850\n",
        "\n",
        "    out_vid = os.path.join(video_root, \"input_vid\")\n",
        "    out_abd = os.path.join(video_root, \"abdomen_mask\")\n",
        "    out_fb  = os.path.join(video_root, \"front_body_mask\")\n",
        "\n",
        "    # clean and recreate input folders\n",
        "    _reset_dir(out_vid)\n",
        "    _reset_dir(out_abd)\n",
        "    _reset_dir(out_fb)\n",
        "\n",
        "    # scene: 5 abdomens (2 stationary feeding, 1 stationary quiet, 2 moving)\n",
        "    A = [\n",
        "        dict(cx=375.0, cy=420.0, a=28, b=18, axis_deg=0.0,   dir_sign=+1, kind=\"stationary_feed\"),\n",
        "        dict(cx=435.0, cy=420.0, a=28, b=18, axis_deg=180.0, dir_sign=+1, kind=\"stationary_feed\"),\n",
        "        dict(cx=200.0, cy=220.0, a=26, b=16, axis_deg=45.0,  dir_sign=+1, kind=\"stationary_quiet\"),\n",
        "        dict(cx=620.0, cy=320.0, a=26, b=16, axis_deg=75.0,  dir_sign=+1, kind=\"moving\"),\n",
        "        dict(cx=180.0, cy=600.0, a=30, b=20, axis_deg=135.0, dir_sign=+1, kind=\"moving\"),\n",
        "    ]\n",
        "    vel = {3: (+0.8, +0.5), 4: (+0.6, -0.7)}  # indices into A\n",
        "\n",
        "    # static noise map to create consistent red boost regions over time\n",
        "    noise = rng.random((H, W))  # float64 0..1 is fine\n",
        "\n",
        "    # step schedule ensures detectable Δ in red proportion\n",
        "    steps = [0.10, 0.32, 0.55, 0.30]\n",
        "    step_len = max(5, n_frames // len(steps))\n",
        "\n",
        "    for t in range(n_frames):\n",
        "        comp_rgb = np.full((H, W, 3), 235, np.uint8)  # light background\n",
        "        abd_mask_all = np.zeros((H, W), np.uint8)\n",
        "        fb_mask_all  = np.zeros((H, W), np.uint8)\n",
        "        red_hi_all   = np.zeros((H, W), dtype=bool)\n",
        "\n",
        "        k = min(t // step_len, len(steps) - 1)\n",
        "        p_feed, p_quiet = steps[k], 0.10\n",
        "\n",
        "        for i, a in enumerate(A):\n",
        "            if a[\"kind\"] == \"moving\":\n",
        "                dx, dy = vel[i]\n",
        "                a[\"cx\"] += dx; a[\"cy\"] += dy\n",
        "                # bounce within margins\n",
        "                if not (80 < a[\"cx\"] < W - 80): vel[i] = (-dx, dy); a[\"cx\"] = np.clip(a[\"cx\"], 80, W - 80)\n",
        "                if not (80 < a[\"cy\"] < H - 80): vel[i] = (dx, -dy); a[\"cy\"] = np.clip(a[\"cy\"], 80, H - 80)\n",
        "\n",
        "            cx, cy = a[\"cx\"], a[\"cy\"]\n",
        "            m_abd = _ellipse_mask(H, W, cx, cy, a[\"a\"], a[\"b\"], a[\"axis_deg\"])\n",
        "            m_fb  = _triangle_wedge(H, W, cx, cy, a[\"axis_deg\"], a[\"dir_sign\"], length=60, base=30)\n",
        "\n",
        "            abd_mask_all |= (m_abd > 0).astype(np.uint8)\n",
        "            fb_mask_all  |= (m_fb  > 0).astype(np.uint8)\n",
        "\n",
        "            p = p_feed if a[\"kind\"] == \"stationary_feed\" else p_quiet\n",
        "            red_hi_all |= (noise < p) & (m_abd > 0)\n",
        "\n",
        "        # compose RGB: dark body; base red inside abdomen; extra bright red on \"feeding\" pixels\n",
        "        comp_rgb[abd_mask_all > 0] = (60, 60, 60)   # dark body\n",
        "        comp_rgb[..., 0][abd_mask_all > 0] = 120    # base red\n",
        "        comp_rgb[..., 0][red_hi_all] = 220          # boosted red (feeding)\n",
        "\n",
        "        base = f\"{prefix}{start_index + t:0{pad}d}.png\"\n",
        "        iio.imwrite(os.path.join(out_vid, base), comp_rgb)                          # RGB\n",
        "        iio.imwrite(os.path.join(out_abd, base), (abd_mask_all * 255).astype(np.uint8))  # 0/255\n",
        "        iio.imwrite(os.path.join(out_fb,  base), (fb_mask_all  * 255).astype(np.uint8))  # 0/255\n",
        "\n",
        "        if (t + 1) % 20 == 0 or t == n_frames - 1:\n",
        "            print(f\"[fake {t+1}/{n_frames}] wrote {base}\")\n",
        "\n",
        "    print(\n",
        "        \"Fake data ready:\",\n",
        "        f\"\\n  input_vid:        {len(os.listdir(out_vid))} PNGs\",\n",
        "        f\"\\n  abdomen_mask:     {len(os.listdir(out_abd))} PNGs\",\n",
        "        f\"\\n  front_body_mask:  {len(os.listdir(out_fb))} PNGs\",\n",
        "    )\n",
        "\n",
        "# -- convenience runner --------------------------------------\n",
        "def run_fake_local(\n",
        "    P: dict,\n",
        "    video_root: str = FAKE_VIDEO_ROOT,\n",
        "    debug: bool = True,\n",
        "    debug_frame: int = 30,\n",
        "    n_frames: int = 60,\n",
        "    rebuild: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate fake data under `video_root` (local) and invoke the detector:\n",
        "        process_video_root(video_root, P, debug=..., debug_frame=...)\n",
        "    Set rebuild=True to wipe any existing fake input folders before generating.\n",
        "    \"\"\"\n",
        "    if rebuild and os.path.isdir(video_root):\n",
        "        shutil.rmtree(video_root, ignore_errors=True)\n",
        "    os.makedirs(video_root, exist_ok=True)\n",
        "\n",
        "    # (Re)generate inputs if missing or on rebuild\n",
        "    if rebuild or not all(os.path.isdir(os.path.join(video_root, d)) for d in (\"input_vid\",\"abdomen_mask\",\"front_body_mask\")):\n",
        "        generate_fake_troph_data(video_root, n_frames=n_frames, seed=0)\n",
        "\n",
        "    # rely on detector’s process_video_root (defined in your detector cell)\n",
        "    return process_video_root(video_root, P, debug=debug, debug_frame=debug_frame)\n"
      ],
      "metadata": {
        "id": "Khqsnd8oKsXR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 3 Orchestrator"
      ],
      "metadata": {
        "id": "6NIY_94p8DAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3 — Orchestrator (TAR-only; exports *_simp.tar; optional raw copy; uses FIELD_PARAMS) ===\n",
        "# Expects from Config (Cell 1):\n",
        "#   RUN_FAKE, RUN_TEST, RUN_BATCH : bool\n",
        "#   FIELD_PARAMS                  : dict   <-- used for all runs\n",
        "#   TEST_VIDEO_ROOT               : str    (Drive stub folder path; TAR is stub + \".tar\")\n",
        "#   BATCH_ROOT                    : str    (Drive parent folder for stubs)\n",
        "#   BATCH_DIR_LIST                : str    (path to .txt list of stub names or absolute paths)\n",
        "#   DEBUG                         : bool\n",
        "#   DEBUG_FRAME                   : int\n",
        "# Optional:\n",
        "#   KEEP_LOCAL                    : bool   (keep staged local copy after run)\n",
        "#   COPY_RAW_OUTPUTS              : bool   (default False; also copy raw outputs back to Drive)\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "REQUIRED_INPUTS = (\"input_vid\", \"abdomen_mask\", \"front_body_mask\")\n",
        "\n",
        "def _iter_batch_roots(batch_root: str, list_file: str):\n",
        "    \"\"\"Yield absolute stub folder paths from a list file.\n",
        "    - Lines can be relative names (joined to batch_root) or absolute paths.\n",
        "    - We *do not* add '.tar' here; the staging wrapper does that.\n",
        "    - Ignores empty lines and lines starting with '#'.\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(list_file):\n",
        "        print(f\"[batch] list file not found: {list_file}\")\n",
        "        return\n",
        "    with open(list_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            name = line.strip()\n",
        "            if not name or name.startswith(\"#\"):\n",
        "                continue\n",
        "            yield name if os.path.isabs(name) else os.path.join(batch_root, name)\n",
        "\n",
        "def _need(varname: str):\n",
        "    if varname not in globals():\n",
        "        raise RuntimeError(f\"Config variable `{varname}` is not defined. Please set it in the Config cell.\")\n",
        "    return globals()[varname]\n",
        "\n",
        "def run_all_from_config():\n",
        "    \"\"\"Run fake/test/batch according to Config flags. Returns a summary dict.\"\"\"\n",
        "    params           = _need(\"FIELD_PARAMS\")\n",
        "    run_fake         = bool(globals().get(\"RUN_FAKE\", False))\n",
        "    run_test         = bool(globals().get(\"RUN_TEST\", False))\n",
        "    run_batch        = bool(globals().get(\"RUN_BATCH\", False))\n",
        "    debug            = bool(globals().get(\"DEBUG\", False))\n",
        "    debug_frame      = int(globals().get(\"DEBUG_FRAME\", 30))\n",
        "    keep_local       = bool(globals().get(\"KEEP_LOCAL\", False))\n",
        "    copy_raw_outputs = bool(globals().get(\"COPY_RAW_OUTPUTS\", False))\n",
        "\n",
        "    summary = {\"fake\": None, \"test\": None, \"batch\": None}\n",
        "    t0 = time.time()\n",
        "\n",
        "    # --- FAKE (always local; no packaging requirement for Drive) ---\n",
        "    if run_fake:\n",
        "        print(\"[orchestrator] RUN_FAKE = True → run_fake_local()\")\n",
        "        try:\n",
        "            run_fake_local(P=params, debug=debug, debug_frame=debug_frame)\n",
        "            summary[\"fake\"] = \"ok\"\n",
        "        except Exception as e:\n",
        "            print(f\"[fake] ❌ {e}\")\n",
        "            summary[\"fake\"] = f\"error: {e}\"\n",
        "\n",
        "    # --- TEST (TAR-only; stub + '.tar'; exports *_simp.tar) ---\n",
        "    if run_test:\n",
        "        test_root = _need(\"TEST_VIDEO_ROOT\")\n",
        "        print(f\"[orchestrator] RUN_TEST = True → {test_root} (.tar consumed; *_simp.tar produced)\")\n",
        "        try:\n",
        "            process_video_root_localfirst(\n",
        "                drive_video_root=test_root,\n",
        "                P=params,\n",
        "                debug=debug,\n",
        "                debug_frame=debug_frame,\n",
        "                keep_local=keep_local,\n",
        "                copy_raw_outputs=copy_raw_outputs,\n",
        "            )\n",
        "            summary[\"test\"] = \"ok\"\n",
        "        except Exception as e:\n",
        "            print(f\"[test] ❌ {e}\")\n",
        "            summary[\"test\"] = f\"error: {e}\"\n",
        "\n",
        "    # --- BATCH (iterate stubs; TAR-only; exports *_simp.tar per stub) ---\n",
        "    if run_batch:\n",
        "        batch_root    = _need(\"BATCH_ROOT\")\n",
        "        batch_list_fn = _need(\"BATCH_DIR_LIST\")\n",
        "        print(f\"[orchestrator] RUN_BATCH = True → list: {batch_list_fn}\")\n",
        "        ok = 0\n",
        "        fail = 0\n",
        "        failures = []\n",
        "        for stub in _iter_batch_roots(batch_root, batch_list_fn):\n",
        "            try:\n",
        "                print(f\"[batch] processing: {stub} (.tar consumed; *_simp.tar produced)\")\n",
        "                process_video_root_localfirst(\n",
        "                    drive_video_root=stub,\n",
        "                    P=params,\n",
        "                    debug=debug,              # honor DEBUG for batch\n",
        "                    debug_frame=debug_frame,\n",
        "                    keep_local=False,\n",
        "                    copy_raw_outputs=copy_raw_outputs,\n",
        "                )\n",
        "                ok += 1\n",
        "            except Exception as e:\n",
        "                fail += 1\n",
        "                failures.append((stub, str(e)))\n",
        "                print(f\"[batch] ❌ {stub}: {e}\")\n",
        "        summary[\"batch\"] = {\"success\": ok, \"fail\": fail, \"failures\": failures}\n",
        "\n",
        "    print(f\"[orchestrator] done in {time.time()-t0:.1f}s\")\n",
        "    return summary\n",
        "\n",
        "# Tip:\n",
        "# RESULT = run_all_from_config()\n",
        "# RESULT\n"
      ],
      "metadata": {
        "id": "Bbsw5C_Ly_pZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 4 Entry point"
      ],
      "metadata": {
        "id": "4qG592Id8IMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4 — Entry point ===\n",
        "from pprint import pprint\n",
        "import time\n",
        "\n",
        "print(\"[entry] starting run_all_from_config() …\")\n",
        "t0 = time.time()\n",
        "try:\n",
        "    RESULT = run_all_from_config()\n",
        "finally:\n",
        "    print(f\"[entry] finished in {time.time()-t0:.1f}s\")\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "pprint(RESULT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2kPp7DEzz-Q",
        "outputId": "0f244c7c-f2e1-41f1-95ba-daba764bccda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[entry] starting run_all_from_config() …\n",
            "[orchestrator] RUN_BATCH = True → list: /content/drive/MyDrive/MainConnection_VidRoots/batch_dir_list.txt\n",
            "[batch] processing: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3 (.tar consumed; *_simp.tar produced)\n",
            "[stage] Using TAR -> local: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3.tar -> /content/_localstage/tmpvidroot3\n",
            "[sanity] input_vid: 132 PNGs head=['frame_000001.png', 'frame_000002.png'] tail=['frame_000131.png', 'frame_000132.png']\n",
            "[sanity] abdomen_mask: 132 PNGs head=['frame_00001.png', 'frame_00002.png'] tail=['frame_00131.png', 'frame_00132.png']\n",
            "[sanity] front_body_mask: 132 PNGs head=['frame_000386.png', 'frame_000387.png'] tail=['frame_000516.png', 'frame_000517.png']\n",
            "[stage] Stage-in done in 0.4s\n",
            "[stage] Using debug_frame=3 (clamped)\n",
            "[run] process_video_root(...) on local copy\n",
            "[25/132]\n",
            "[50/132]\n",
            "[75/132]\n",
            "[100/132]\n",
            "[125/132]\n",
            "[132/132]\n",
            "Done.\n",
            "[run] done in 50.0s\n",
            "[export] Packaging result to: /content/_localstage/tmpvidroot3_simp.tar\n",
            "[export] Uploading packaged tar to Drive: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3_simp.tar\n",
            "[export] Packaging + upload done in 0.4s\n",
            "[stage] Skipping raw output copy (COPY_RAW_OUTPUTS=False).\n",
            "[stage] Local staging cleaned\n",
            "[batch] processing: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot4 (.tar consumed; *_simp.tar produced)\n",
            "[stage] Using TAR -> local: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot4.tar -> /content/_localstage/tmpvidroot4\n",
            "[sanity] input_vid: 84 PNGs head=['frame_000001.png', 'frame_000002.png'] tail=['frame_000083.png', 'frame_000084.png']\n",
            "[sanity] abdomen_mask: 84 PNGs head=['frame_00001.png', 'frame_00002.png'] tail=['frame_00083.png', 'frame_00084.png']\n",
            "[sanity] front_body_mask: 84 PNGs head=['frame_000266.png', 'frame_000267.png'] tail=['frame_000348.png', 'frame_000349.png']\n",
            "[stage] Stage-in done in 0.2s\n",
            "[stage] Using debug_frame=3 (clamped)\n",
            "[run] process_video_root(...) on local copy\n",
            "[25/84]\n",
            "[50/84]\n",
            "[75/84]\n",
            "[84/84]\n",
            "Done.\n",
            "[run] done in 22.5s\n",
            "[export] Packaging result to: /content/_localstage/tmpvidroot4_simp.tar\n",
            "[export] Uploading packaged tar to Drive: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot4_simp.tar\n",
            "[export] Packaging + upload done in 0.3s\n",
            "[stage] Skipping raw output copy (COPY_RAW_OUTPUTS=False).\n",
            "[stage] Local staging cleaned\n",
            "[batch] processing: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot5 (.tar consumed; *_simp.tar produced)\n",
            "[stage] Using TAR -> local: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot5.tar -> /content/_localstage/tmpvidroot5\n",
            "[sanity] input_vid: 102 PNGs head=['frame_000001.png', 'frame_000002.png'] tail=['frame_000101.png', 'frame_000102.png']\n",
            "[sanity] abdomen_mask: 102 PNGs head=['frame_00001.png', 'frame_00002.png'] tail=['frame_00101.png', 'frame_00102.png']\n",
            "[sanity] front_body_mask: 102 PNGs head=['frame_000253.png', 'frame_000254.png'] tail=['frame_000353.png', 'frame_000354.png']\n",
            "[stage] Stage-in done in 0.2s\n",
            "[stage] Using debug_frame=3 (clamped)\n",
            "[run] process_video_root(...) on local copy\n",
            "[25/102]\n",
            "[50/102]\n",
            "[75/102]\n",
            "[100/102]\n",
            "[102/102]\n",
            "Done.\n",
            "[run] done in 30.3s\n",
            "[export] Packaging result to: /content/_localstage/tmpvidroot5_simp.tar\n",
            "[export] Uploading packaged tar to Drive: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot5_simp.tar\n",
            "[export] Packaging + upload done in 0.3s\n",
            "[stage] Skipping raw output copy (COPY_RAW_OUTPUTS=False).\n",
            "[stage] Local staging cleaned\n",
            "[batch] processing: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot6 (.tar consumed; *_simp.tar produced)\n",
            "[stage] Using TAR -> local: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot6.tar -> /content/_localstage/tmpvidroot6\n",
            "[sanity] input_vid: 96 PNGs head=['frame_000001.png', 'frame_000002.png'] tail=['frame_000095.png', 'frame_000096.png']\n",
            "[sanity] abdomen_mask: 96 PNGs head=['frame_00001.png', 'frame_00002.png'] tail=['frame_00095.png', 'frame_00096.png']\n",
            "[sanity] front_body_mask: 96 PNGs head=['frame_000067.png', 'frame_000068.png'] tail=['frame_000161.png', 'frame_000162.png']\n",
            "[stage] Stage-in done in 0.2s\n",
            "[stage] Using debug_frame=3 (clamped)\n",
            "[run] process_video_root(...) on local copy\n",
            "[25/96]\n",
            "[50/96]\n",
            "[75/96]\n",
            "[96/96]\n",
            "Done.\n",
            "[run] done in 28.2s\n",
            "[export] Packaging result to: /content/_localstage/tmpvidroot6_simp.tar\n",
            "[export] Uploading packaged tar to Drive: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot6_simp.tar\n",
            "[export] Packaging + upload done in 0.7s\n",
            "[stage] Skipping raw output copy (COPY_RAW_OUTPUTS=False).\n",
            "[stage] Local staging cleaned\n",
            "[orchestrator] done in 133.9s\n",
            "[entry] finished in 133.9s\n",
            "\n",
            "=== Summary ===\n",
            "{'batch': {'fail': 0, 'failures': [], 'success': 4}, 'fake': None, 'test': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run up to this point\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "1hUdZK6Qz0XI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i0FsXWR2z0y4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "padv_pUDN4kl"
      }
    }
  ]
}