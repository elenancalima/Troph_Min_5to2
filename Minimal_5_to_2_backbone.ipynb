{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMo2Rxw6YR7kaRaVx2qR7uj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elenancalima/Troph_Min_5to2/blob/main/Minimal_5_to_2_backbone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PIP-only, GPU-capable stack (T4 / CUDA 12.1)\n",
        "# - numpy==1.26.4  (avoids NumPy 2.x ABI churn in Colab)\n",
        "# - torch==2.4.1 (cu121)\n",
        "# - pillow (PNG I/O)\n",
        "import subprocess, sys, os\n",
        "\n",
        "def sh(cmd):\n",
        "    print(\"$\", cmd)\n",
        "    r = subprocess.run(cmd, shell=True)\n",
        "    if r.returncode != 0:\n",
        "        raise SystemExit(f\"Command failed: {cmd}\")\n",
        "\n",
        "# Remove potentially conflicting preinstalls\n",
        "sh(\"pip -q uninstall -y torch torchvision torchaudio numpy || true\")\n",
        "\n",
        "# Pin NumPy FIRST\n",
        "sh(\"pip -q install --no-deps --only-binary=:all: numpy==1.26.4\")\n",
        "\n",
        "# PyTorch for CUDA 12.1 (works on CPU too; will use GPU if present)\n",
        "TORCH_IDX = \"https://download.pytorch.org/whl/cu121\"\n",
        "sh(f\"pip -q install --index-url {TORCH_IDX} torch==2.4.1\")\n",
        "\n",
        "# Pillow for PNG I/O\n",
        "sh(\"pip -q install --upgrade pillow\")\n",
        "\n",
        "print(\"✅ Installed. The runtime will now restart to load the new NumPy cleanly...\")\n",
        "# Hard restart so the new binary NumPy is used (prevents dtype-size mismatch).\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25amoGnx5NLA",
        "outputId": "a8ef4943-2718-4971-fcb3-061c229fcd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ pip -q uninstall -y torch torchvision torchaudio numpy || true\n",
            "$ pip -q install --no-deps --only-binary=:all: numpy==1.26.4\n",
            "$ pip -q install --index-url https://download.pytorch.org/whl/cu121 torch==2.4.1\n",
            "$ pip -q install --upgrade pillow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BELOW SETUP IS UNTESTED"
      ],
      "metadata": {
        "id": "zU9Ar19r9fL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Smart, GPU-ready setup for Colab (T4). Reuses preinstalls if healthy.\n",
        "import os, sys, subprocess\n",
        "\n",
        "def sh(cmd):\n",
        "    print(\"$\", cmd)\n",
        "    r = subprocess.run(cmd, shell=True)\n",
        "    return r.returncode == 0\n",
        "\n",
        "def torch_ok():\n",
        "    try:\n",
        "        import torch\n",
        "        # Needs to be CUDA-enabled and have a known CUDA build (prefer cu121 for T4)\n",
        "        if not torch.cuda.is_available(): return False\n",
        "        cu = getattr(torch.version, \"cuda\", None) or \"\"\n",
        "        # Accept cu121 (preferred) or anything 12.x that actually runs on GPU\n",
        "        return cu.startswith(\"12\")  # keep flexible, but you can tighten to \"12.1\"\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def numpy_ok():\n",
        "    try:\n",
        "        import numpy as np\n",
        "        # Quick sanity: can we import compiled random pieces?\n",
        "        import numpy.random._bounded_integers  # fails if ABI mismatch\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "need_torch = not torch_ok()\n",
        "need_numpy = not numpy_ok()\n",
        "\n",
        "print(f\"precheck -> need_numpy={need_numpy}, need_torch={need_torch}\")\n",
        "\n",
        "if need_numpy or need_torch:\n",
        "    # Clean conflicting wheels first to avoid mixed ABIs\n",
        "    sh(\"pip -q uninstall -y torch torchvision torchaudio numpy || true\")\n",
        "    # Pin NumPy FIRST to avoid ABI churn\n",
        "    if not sh(\"pip -q install --no-deps --only-binary=:all: numpy==1.26.4\"):\n",
        "        raise SystemExit(\"Failed to install numpy 1.26.4\")\n",
        "    # Install a GPU-capable Torch (cu121 works well on T4)\n",
        "    TORCH_IDX = \"https://download.pytorch.org/whl/cu121\"\n",
        "    if not sh(f\"pip -q install --index-url {TORCH_IDX} torch==2.4.1\"):\n",
        "        raise SystemExit(\"Failed to install torch 2.4.1 (cu121)\")\n",
        "    # Pillow for PNG I/O\n",
        "    sh(\"pip -q install --upgrade pillow\")\n",
        "    print(\"✅ Installed fixed stack. Restarting kernel to load cleanly…\")\n",
        "    os.kill(os.getpid(), 9)\n",
        "else:\n",
        "    print(\"✅ Environment looks good—no reinstall needed.\")\n"
      ],
      "metadata": {
        "id": "9uATrncj7CQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACTUAL RUN STARTS HERE"
      ],
      "metadata": {
        "id": "sax5jtmb9irT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, torch, PIL, platform, sys\n",
        "print(\"python\", sys.version.split()[0], \"|\", platform.platform())\n",
        "print(\"numpy\", np.__version__)\n",
        "print(\"torch\", torch.__version__, \"cuda?\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"cuda device:\", torch.cuda.get_device_name(0))\n",
        "print(\"pillow\", PIL.__version__)\n",
        "\n",
        "# Deterministic-ish\n",
        "import random\n",
        "random.seed(0); np.random.seed(0); torch.manual_seed(0)\n",
        "try:\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "except Exception:\n",
        "    pass\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LshZa-ljQroz",
        "outputId": "960d8f07-d059-46a5-a8a9-9a323dd65ec2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python 3.12.12 | Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "numpy 1.26.4\n",
            "torch 2.4.1+cu121 cuda? True\n",
            "cuda device: Tesla T4\n",
            "pillow 11.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Stage 1: RGB (850→170) -> 2 dense maps @170x170\n",
        "class Stage1Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 2, 1)\n",
        "        )\n",
        "    def forward(self, x170_rgb):\n",
        "        return torch.sigmoid(self.net(x170_rgb))  # (B,2,170,170)\n",
        "\n",
        "# Stage 2: concat [2 stage1 + 1 abdomen + 1 front + 1 simple_troph + 1 simple_part] -> 2 final maps\n",
        "class Stage2Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(6, 16, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 2, 1)\n",
        "        )\n",
        "    def forward(self, x6):\n",
        "        return torch.sigmoid(self.net(x6))       # (B,2,170,170)\n",
        "\n",
        "stage1 = Stage1Net().to(device).eval()\n",
        "stage2 = Stage2Net().to(device).eval()\n"
      ],
      "metadata": {
        "id": "WrJNyehc8OWX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, glob\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "TARGET_850 = (850, 850)   # (W,H) for Pillow\n",
        "TARGET_170 = (170, 170)\n",
        "\n",
        "def ensure_exists(*folders):\n",
        "    for d in folders:\n",
        "        if not os.path.isdir(d):\n",
        "            raise RuntimeError(f\"Required folder missing: {d}\")\n",
        "\n",
        "def list_indexed_pngs(folder):\n",
        "    paths = sorted(glob.glob(os.path.join(folder, \"*.png\")))\n",
        "    if not paths:\n",
        "        raise RuntimeError(f\"No .png found in: {folder}\")\n",
        "    items = []\n",
        "    seen = set()\n",
        "    for p in paths:\n",
        "        m = re.search(r'(\\d+)(?=\\D*$)', os.path.basename(p))  # last digit block\n",
        "        if not m:\n",
        "            raise RuntimeError(f\"No numeric frame index in filename: {p}\")\n",
        "        s = m.group(1); idx = int(s); pad = len(s)\n",
        "        if idx in seen:\n",
        "            raise RuntimeError(f\"Duplicate frame index {idx} in {folder}\")\n",
        "        seen.add(idx)\n",
        "        items.append((idx, p, pad))\n",
        "    d = {idx: p for idx, p, _ in items}\n",
        "    pad_width = max(pad for _,_,pad in items)\n",
        "    return d, pad_width\n",
        "\n",
        "def load_rgb_850_as_tensor(path):\n",
        "    im = Image.open(path).convert(\"RGB\")\n",
        "    if im.size != TARGET_850:\n",
        "        raise RuntimeError(f\"input_vid must be 850x850 (W,H); got {im.size} for {path}\")\n",
        "    arr = np.asarray(im, dtype=np.float32) / 255.0      # (H,W,3)\n",
        "    return torch.from_numpy(arr).permute(2,0,1).unsqueeze(0)  # (1,3,850,850)\n",
        "\n",
        "def load_bin_850_as_tensor01(path):\n",
        "    im = Image.open(path).convert(\"L\")\n",
        "    if im.size != TARGET_850:\n",
        "        raise RuntimeError(f\"Binary 850 must be 850x850 (W,H); got {im.size} for {path}\")\n",
        "    arr = (np.asarray(im, dtype=np.uint8) >= 128).astype(np.float32)  # 0/1\n",
        "    return torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)            # (1,1,850,850)\n",
        "\n",
        "def load_bin_170_as_tensor01(path):\n",
        "    im = Image.open(path).convert(\"L\")\n",
        "    if im.size != TARGET_170:\n",
        "        raise RuntimeError(f\"Binary 170 must be 170x170 (W,H); got {im.size} for {path}\")\n",
        "    arr = (np.asarray(im, dtype=np.uint8) >= 128).astype(np.float32)\n",
        "    return torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)            # (1,1,170,170)\n",
        "\n",
        "def save_binary_170_png(path, t01):\n",
        "    if t01.ndim == 4: t01 = t01[0,0]\n",
        "    arr = (t01.cpu().numpy() >= 0.5).astype(np.uint8) * 255\n",
        "    Image.fromarray(arr, mode=\"L\").save(path)\n"
      ],
      "metadata": {
        "id": "4KLxHfT88QS2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(video_root: str, threshold: float = 0.5, verbose_first=False):\n",
        "    # Inputs\n",
        "    d_in   = os.path.join(video_root, \"input_vid\")\n",
        "    d_abd  = os.path.join(video_root, \"abdomen_mask\")\n",
        "    d_fb   = os.path.join(video_root, \"front_body_mask\")\n",
        "    d_st   = os.path.join(video_root, \"simple_troph_point_heatmap\")\n",
        "    d_spl  = os.path.join(video_root, \"simple_participant_line_heatmap\")\n",
        "    ensure_exists(d_in, d_abd, d_fb, d_st, d_spl)\n",
        "\n",
        "    # Outputs\n",
        "    d_out_tp  = os.path.join(video_root, \"pred_troph_point\")\n",
        "    d_out_pl  = os.path.join(video_root, \"pred_participant_line\")\n",
        "    Path(d_out_tp).mkdir(parents=True, exist_ok=True)\n",
        "    Path(d_out_pl).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Index maps (idx -> path) and pad width from input_vid\n",
        "    M_in,  pad_width = list_indexed_pngs(d_in)\n",
        "    M_abd, _ = list_indexed_pngs(d_abd)\n",
        "    M_fb,  _ = list_indexed_pngs(d_fb)\n",
        "    M_st,  _ = list_indexed_pngs(d_st)\n",
        "    M_spl, _ = list_indexed_pngs(d_spl)\n",
        "\n",
        "    S_in, S_abd, S_fb, S_st, S_spl = map(set, (M_in.keys(), M_abd.keys(), M_fb.keys(), M_st.keys(), M_spl.keys()))\n",
        "    if not (S_in == S_abd == S_fb == S_st == S_spl):\n",
        "        all_idx = sorted(S_in | S_abd | S_fb | S_st | S_spl)\n",
        "        def miss(name, S):\n",
        "            missing = [i for i in all_idx if i not in S]\n",
        "            return f\"{name}: missing {len(missing)} → {missing[:20]}{' ...' if len(missing)>20 else ''}\"\n",
        "        msg = \"Frame-index mismatch across folders:\\n  \" + \"\\n  \".join([\n",
        "            miss(\"input_vid\", S_in), miss(\"abdomen_mask\", S_abd), miss(\"front_body_mask\", S_fb),\n",
        "            miss(\"simple_troph_point_heatmap\", S_st), miss(\"simple_participant_line_heatmap\", S_spl)\n",
        "        ])\n",
        "        raise RuntimeError(msg)\n",
        "\n",
        "    idx_list = sorted(S_in); n = len(idx_list)\n",
        "    print(f\"[OK] Found {n} aligned frame indices under: {video_root}\")\n",
        "    print(f\"     Writing 170×170 binaries to:\\n       {d_out_tp}\\n       {d_out_pl}\")\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for k, idx in enumerate(idx_list):\n",
        "            # --- load to CPU\n",
        "            x_rgb850 = load_rgb_850_as_tensor(M_in[idx])\n",
        "            abd850   = load_bin_850_as_tensor01(M_abd[idx])\n",
        "            fb850    = load_bin_850_as_tensor01(M_fb[idx])\n",
        "            st170    = load_bin_170_as_tensor01(M_st[idx])\n",
        "            spl170   = load_bin_170_as_tensor01(M_spl[idx])\n",
        "\n",
        "            # --- move to device\n",
        "            x_rgb850 = x_rgb850.to(device, non_blocking=True)\n",
        "            abd850   = abd850.to(device, non_blocking=True)\n",
        "            fb850    = fb850.to(device, non_blocking=True)\n",
        "            st170    = st170.to(device, non_blocking=True)\n",
        "            spl170   = spl170.to(device, non_blocking=True)\n",
        "\n",
        "            # --- downsample to 170\n",
        "            x_rgb170 = F.interpolate(x_rgb850, size=(170,170), mode=\"bilinear\", align_corners=False)\n",
        "            abd170   = F.interpolate(abd850,   size=(170,170), mode=\"nearest\")\n",
        "            fb170    = F.interpolate(fb850,    size=(170,170), mode=\"nearest\")\n",
        "\n",
        "            # --- Stage 1 & 2\n",
        "            f12 = stage1(x_rgb170)                                   # (1,2,170,170)\n",
        "            x6  = torch.cat([f12, abd170, fb170, st170, spl170], dim=1)  # (1,6,170,170)\n",
        "            y2  = stage2(x6)                                          # (1,2,170,170)\n",
        "\n",
        "            if verbose_first and k == 0:\n",
        "                print(\"Shapes @first:\",\n",
        "                      \"f12\", tuple(f12.shape),\n",
        "                      \"abd\", tuple(abd170.shape),\n",
        "                      \"fb\",  tuple(fb170.shape),\n",
        "                      \"st\",  tuple(st170.shape),\n",
        "                      \"spl\", tuple(spl170.shape))\n",
        "\n",
        "            # --- save (threshold to binary)\n",
        "            a = (y2[:,0:1] >= threshold).float()\n",
        "            b = (y2[:,1:2] >= threshold).float()\n",
        "            save_binary_170_png(os.path.join(d_out_tp, f\"{idx:0{pad_width}d}.png\"), a)\n",
        "            save_binary_170_png(os.path.join(d_out_pl, f\"{idx:0{pad_width}d}.png\"), b)\n",
        "\n",
        "            if (k+1) % 100 == 0 or k == n-1:\n",
        "                print(f\"  processed {k+1}/{n}\")\n",
        "\n",
        "    print(\"[DONE] Inference complete.\")\n"
      ],
      "metadata": {
        "id": "gp5BKixK8Uqk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import os, glob\n",
        "from pathlib import Path\n",
        "\n",
        "VIDEO_ROOT = \"/content/fake_video_root_t4\"\n",
        "for sd in [\"input_vid\",\"abdomen_mask\",\"front_body_mask\",\"simple_troph_point_heatmap\",\"simple_participant_line_heatmap\"]:\n",
        "    Path(os.path.join(VIDEO_ROOT, sd)).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "H=W=850; h=w=170; N=20\n",
        "for i in range(N):\n",
        "    # input 850 rgb\n",
        "    img = Image.new(\"RGB\", (W,H), (0,0,0))\n",
        "    d = ImageDraw.Draw(img)\n",
        "    d.ellipse([(100+(i*7)%W-40,200-40),(100+(i*7)%W+40,200+40)], fill=(40,120,240))\n",
        "    d.rectangle([(300,300),(500,500)], fill=(200,60,60))\n",
        "    d.text((600,100), f\"{i+1:03d}\", fill=(210,210,210))\n",
        "    img.save(os.path.join(VIDEO_ROOT,\"input_vid\",f\"frame_{i+1:05d}.png\"))\n",
        "\n",
        "    # abdomen 850 bin\n",
        "    a = Image.new(\"L\", (W,H), 0); d = ImageDraw.Draw(a)\n",
        "    d.ellipse([(200+(i*5)%W-120,600-120),(200+(i*5)%W+120,600+120)], fill=255)\n",
        "    a.save(os.path.join(VIDEO_ROOT,\"abdomen_mask\",f\"frame_{i+1:05d}.png\"))\n",
        "\n",
        "    # front 850 bin\n",
        "    f = Image.new(\"L\", (W,H), 0); d = ImageDraw.Draw(f)\n",
        "    y = (i*9) % H; d.line([(50,y),(W-50,y)], fill=255, width=5)\n",
        "    f.save(os.path.join(VIDEO_ROOT,\"front_body_mask\",f\"frame_{i+1:05d}.png\"))\n",
        "\n",
        "    # simple 170 bins\n",
        "    s1 = Image.new(\"L\", (w,h), 0); d = ImageDraw.Draw(s1)\n",
        "    d.ellipse([(20+(i*3)%w-3,30-3),(20+(i*3)%w+3,30+3)], fill=255)\n",
        "    s1.save(os.path.join(VIDEO_ROOT,\"simple_troph_point_heatmap\",f\"frame_{i+1:05d}.png\"))\n",
        "\n",
        "    s2 = Image.new(\"L\", (w,h), 0); d = ImageDraw.Draw(s2)\n",
        "    y2 = (i*4) % h; d.line([(10,y2),(w-10,y2)], fill=255, width=1)\n",
        "    s2.save(os.path.join(VIDEO_ROOT,\"simple_participant_line_heatmap\",f\"frame_{i+1:05d}.png\"))\n",
        "\n",
        "print(\"[OK] Fake data at:\", VIDEO_ROOT)\n",
        "run_inference(VIDEO_ROOT, threshold=0.5, verbose_first=True)\n",
        "\n",
        "A = sorted(glob.glob(os.path.join(VIDEO_ROOT, \"pred_troph_point\", \"*.png\")))\n",
        "B = sorted(glob.glob(os.path.join(VIDEO_ROOT, \"pred_participant_line\", \"*.png\")))\n",
        "print(\"Output counts:\", len(A), len(B))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic_67zeC8WO1",
        "outputId": "24849d9c-d0e7-4e01-a643-48a9a3e095fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Fake data at: /content/fake_video_root_t4\n",
            "[OK] Found 20 aligned frame indices under: /content/fake_video_root_t4\n",
            "     Writing 170×170 binaries to:\n",
            "       /content/fake_video_root_t4/pred_troph_point\n",
            "       /content/fake_video_root_t4/pred_participant_line\n",
            "Shapes @first: f12 (1, 2, 170, 170) abd (1, 1, 170, 170) fb (1, 1, 170, 170) st (1, 1, 170, 170) spl (1, 1, 170, 170)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3729539640.py:59: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  Image.fromarray(arr, mode=\"L\").save(path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 20/20\n",
            "[DONE] Inference complete.\n",
            "Output counts: 20 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This takes considerably longer than YOLO inference, beware."
      ],
      "metadata": {
        "id": "sUbtZrkD74FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- Paths you gave ---\n",
        "videoName   = \"FoodLimit2.5D_gR0033_feeding\"\n",
        "GDRIVE_ROOT = \"/content/drive/MyDrive\"\n",
        "VIDEO_ROOT  = f\"{GDRIVE_ROOT}/MainConnection_VidRoots/{videoName}\"  # this is the video root\n",
        "\n",
        "print(\"VIDEO_ROOT =\", VIDEO_ROOT)\n",
        "\n",
        "# Optional: quick peek to confirm subfolders exist (won't list files, just names)\n",
        "import os\n",
        "expected = [\n",
        "    \"input_vid\", \"abdomen_mask\", \"front_body_mask\",\n",
        "    \"simple_troph_point_heatmap\", \"simple_participant_line_heatmap\"\n",
        "]\n",
        "missing = [d for d in expected if not os.path.isdir(os.path.join(VIDEO_ROOT, d))]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"Missing expected subfolders under VIDEO_ROOT: {missing}\")\n",
        "\n",
        "# Run inference (uses GPU if available)\n",
        "run_inference(VIDEO_ROOT, threshold=0.5, verbose_first=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHAa5kYk5YXk",
        "outputId": "893eb223-71f0-4556-f8b0-30bffdbdd9bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "VIDEO_ROOT = /content/drive/MyDrive/MainConnection_VidRoots/FoodLimit2.5D_gR0033_feeding\n",
            "[OK] Found 207 aligned frame indices under: /content/drive/MyDrive/MainConnection_VidRoots/FoodLimit2.5D_gR0033_feeding\n",
            "     Writing 170×170 binaries to:\n",
            "       /content/drive/MyDrive/MainConnection_VidRoots/FoodLimit2.5D_gR0033_feeding/pred_troph_point\n",
            "       /content/drive/MyDrive/MainConnection_VidRoots/FoodLimit2.5D_gR0033_feeding/pred_participant_line\n",
            "Shapes @first: f12 (1, 2, 170, 170) abd (1, 1, 170, 170) fb (1, 1, 170, 170) st (1, 1, 170, 170) spl (1, 1, 170, 170)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3729539640.py:59: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  Image.fromarray(arr, mode=\"L\").save(path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 100/207\n",
            "  processed 200/207\n",
            "  processed 207/207\n",
            "[DONE] Inference complete.\n"
          ]
        }
      ]
    }
  ]
}