{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elenancalima/Troph_Min_5to2/blob/main/Minimal_5_to_2_backbone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz6mG0AuSRmh",
        "outputId": "192a521b-bceb-4b17-d3e8-6343cd27b5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Project dir: /content/drive/MyDrive/Troph_Min_5to_2_mod\n",
            "Torch: 2.8.0+cu126 | CUDA available: True\n",
            "Ultralytics: 8.3.0\n",
            "[weights] Found: /content/drive/MyDrive/Troph_Min_5to_2_mod/yolo11n.pt\n",
            "imageio v3 import: OK\n"
          ]
        }
      ],
      "source": [
        "# === Setup (mount + deps + project path) — weights-only, no datasets ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Pin a stable Ultralytics that doesn't get “creative” on import,\n",
        "# and install imageio for PNG writing.\n",
        "# Using version 8.3.0 to match the yolo11n.pt weights release.\n",
        "%pip -q install -U \"ultralytics==8.3.0\" \"imageio>=2.31.0\"\n",
        "\n",
        "import os, sys, shutil, pathlib, urllib.request, importlib.metadata as im\n",
        "\n",
        "# Work under Drive so artifacts persist\n",
        "PROJ_DIR = \"/content/drive/MyDrive/Troph_Min_5to_2_mod\"\n",
        "os.makedirs(PROJ_DIR, exist_ok=True)\n",
        "os.chdir(PROJ_DIR)\n",
        "if PROJ_DIR not in sys.path:\n",
        "    sys.path.insert(0, PROJ_DIR)\n",
        "\n",
        "print(\"Project dir:\", PROJ_DIR)\n",
        "\n",
        "# Sanity printouts (no ultralytics import here to avoid side-effects)\n",
        "import torch\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
        "try:\n",
        "    print(\"Ultralytics:\", im.version(\"ultralytics\"))\n",
        "except Exception as _e:\n",
        "    print(\"Ultralytics: not found\")\n",
        "\n",
        "# --- Weights-only bootstrap (no YOLO() call here) ---\n",
        "YOLO_WEIGHTS_NAME = \"yolo11n.pt\"\n",
        "YOLO_WEIGHTS_PATH = os.path.join(PROJ_DIR, YOLO_WEIGHTS_NAME)\n",
        "if not os.path.isfile(YOLO_WEIGHTS_PATH):\n",
        "    url = \"https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt\"\n",
        "    print(f\"[weights] Downloading {YOLO_WEIGHTS_NAME}…\")\n",
        "    urllib.request.urlretrieve(url, YOLO_WEIGHTS_PATH)\n",
        "    print(f\"[weights] Ready at: {YOLO_WEIGHTS_PATH}\")\n",
        "else:\n",
        "    print(f\"[weights] Found: {YOLO_WEIGHTS_PATH}\")\n",
        "\n",
        "# Quiet standard logging from the 'ultralytics' logger (prevents banner spam if it appears)\n",
        "import logging\n",
        "logging.getLogger(\"ultralytics\").setLevel(logging.ERROR)\n",
        "\n",
        "# imageio v3 check\n",
        "from imageio import v3 as iio\n",
        "print(\"imageio v3 import: OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "982imcSBEJwO",
        "outputId": "a2e07f28-ab6f-4d0e-acb9-2ac96efa8d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CODE FROM: /content/Troph_Min_5to_2_mod\n",
            "WEIGHTS  : /content/drive/MyDrive/Troph_Min_5to_2_mod/weights\n"
          ]
        }
      ],
      "source": [
        "#@title Fast local dev: mirror code from Drive → /content and import from there\n",
        "\n",
        "import os, sys, subprocess, time\n",
        "\n",
        "# Paths\n",
        "PROJ_DIR_DRIVE = \"/content/drive/MyDrive/Troph_Min_5to_2_mod\"   # source of truth on Drive\n",
        "PROJ_DIR_LOCAL = \"/content/Troph_Min_5to_2_mod\"                  # fast local mirror for imports\n",
        "WEIGHTS_DIR    = f\"{PROJ_DIR_DRIVE}/weights\"                     # keep weights on Drive (persistent)\n",
        "\n",
        "# Drive is already mounted in Cell 1; avoid remounting to prevent race with rsync.\n",
        "# Briefly wait until the Drive folder is actually visible.\n",
        "for _ in range(20):\n",
        "    if os.path.isdir(PROJ_DIR_DRIVE):\n",
        "        break\n",
        "    time.sleep(0.25)\n",
        "\n",
        "os.makedirs(PROJ_DIR_DRIVE, exist_ok=True)\n",
        "os.makedirs(PROJ_DIR_LOCAL, exist_ok=True)\n",
        "\n",
        "# Mirror Drive → local (exclude caches/heavy run dirs)\n",
        "cmd = [\n",
        "    \"rsync\",\"-ah\",\"--delete\",\"--info=stats2\",\n",
        "    \"--exclude\",\"__pycache__/\",\n",
        "    \"--exclude\",\".ipynb_checkpoints/\",\n",
        "    \"--exclude\",\"weights/\",\n",
        "    \"--exclude\",\"runs/\",\n",
        "    PROJ_DIR_DRIVE + \"/\", PROJ_DIR_LOCAL + \"/\"\n",
        "]\n",
        "proc = subprocess.run(cmd, capture_output=True, text=True)\n",
        "if proc.returncode != 0:\n",
        "    # Show rsync diagnostics, then raise the same error Colab would have raised\n",
        "    print(proc.stdout)\n",
        "    print(proc.stderr)\n",
        "    raise subprocess.CalledProcessError(proc.returncode, cmd)\n",
        "\n",
        "# Import from local\n",
        "if PROJ_DIR_LOCAL not in sys.path:\n",
        "    sys.path.insert(0, PROJ_DIR_LOCAL)\n",
        "\n",
        "print(\"CODE FROM:\", PROJ_DIR_LOCAL)\n",
        "print(\"WEIGHTS  :\", WEIGHTS_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaJunSUs8Yk3",
        "outputId": "5557920c-2b3b-40c9-d432-3aea0160d688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports ready (local).\n"
          ]
        }
      ],
      "source": [
        "#@title Import modules from local mirror\n",
        "import importlib\n",
        "\n",
        "import config;          importlib.reload(config)\n",
        "import fake_data;       importlib.reload(fake_data)\n",
        "import folder_dataset;  importlib.reload(folder_dataset)\n",
        "import data_factory;    importlib.reload(data_factory)\n",
        "import model_factory;   importlib.reload(model_factory)\n",
        "import trainer;         importlib.reload(trainer)\n",
        "import pipeline;        importlib.reload(pipeline)\n",
        "import troph;           importlib.reload(troph)\n",
        "\n",
        "from troph import Troph\n",
        "print(\"Imports ready (local).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqYIyNLTISv3"
      },
      "source": [
        "## Config cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1ULSjLfIP0_",
        "outputId": "47780919-687c-4575-af66-10984b0547cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[config] fake_gen= False | fake_train_infer= False | field_train_infer= True | batch= False\n",
            "[config] TRAIN_TAR: /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3_simp.tar\n",
            "[config] VAL_TAR  : /content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot4_simp.tar\n",
            "[config] WEIGHTS  : /content/drive/MyDrive/Troph_Min_5to_2_mod/weights\n",
            "[config] INFER_TMP_ROOT: /content/_troph_tmp_preds\n",
            "[config] SEQ_LEN: 1 | EPOCHS: 10 | FREEZE: 5\n"
          ]
        }
      ],
      "source": [
        "# === Config (control panel) ===\n",
        "# What to run\n",
        "DO_FAKE_GEN            = False   # generate fake train/val folders on disk\n",
        "DO_FAKE_TRAIN_INFER    = False   # train+infer on the fake folders\n",
        "DO_FIELD_TRAIN_INFER   = True    # train+infer on field data from .tar files\n",
        "DO_BATCH_PROCESS       = False   # (reserved) batch predict over many roots\n",
        "\n",
        "# Paths (edit as needed)\n",
        "# Fake (local, fast)\n",
        "FAKE_TRAIN_ROOT = \"/content/fake_train_v1\"\n",
        "FAKE_VAL_ROOT   = \"/content/fake_val_v1\"\n",
        "\n",
        "# Field data (Drive .tar archives → extracted to local)\n",
        "TRAIN_TAR = \"/content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot3_simp.tar\"  # <- EDIT\n",
        "VAL_TAR   = \"/content/drive/MyDrive/MainConnection_VidRoots/tmpvidroot4_simp.tar\"  # <- EDIT\n",
        "\n",
        "# Where to extract those .tars locally\n",
        "LOCAL_TRAIN_ROOT = \"/content/_field_local/train\"\n",
        "LOCAL_VAL_ROOT   = \"/content/_field_local/val\"\n",
        "\n",
        "# Weights (persist on Drive)\n",
        "WEIGHTS_DIR = \"/content/drive/MyDrive/Troph_Min_5to_2_mod/weights\"\n",
        "\n",
        "# Inference temp root (always write locally first, then sync to Drive)\n",
        "INFER_TMP_ROOT = \"/content/_troph_tmp_preds\"   # ← NEW\n",
        "\n",
        "# Training & inference knobs\n",
        "EPOCHS          = 10\n",
        "BATCH_SIZE      = 8\n",
        "NUM_WORKERS     = 0           # 0 is safer with Drive-backed data; local is fine too\n",
        "PROGRESS_EVERY  = 50\n",
        "\n",
        "# Temporal context (TCN-ready; keep 1 until temporal trainer is wired)\n",
        "SEQ_LEN = 1                   # must be odd when >1 (e.g., 3,5,7,...); anchor is the center frame\n",
        "\n",
        "# Label dilation (loss pre-processing)\n",
        "LABEL_DILATE_RADIUS = 4       # px at 170×170 resolution; used in loss label preprocessing\n",
        "\n",
        "# Output & thresholds (for inference binarization)\n",
        "THRESH_TROPH = 0.5\n",
        "THRESH_PART  = 0.5\n",
        "\n",
        "# YOLO backbone (feature encoder for Stage 1)\n",
        "YOLO_BACKBONE_VARIANT = \"yolo11n\"   # informational; we load weights from the path below\n",
        "YOLO_BACKBONE_WEIGHTS = \"/content/drive/MyDrive/_pretrained/yolo11n.pt\"  # COCO-pretrained\n",
        "BACKBONE_FREEZE_EPOCHS = 5          # keep backbone frozen for first N epochs, then unfreeze\n",
        "YOLO_FEATURE_STRIDE    = 5          # we need 850→170; stride 5 aligns features to 170×170\n",
        "\n",
        "print(\"[config] fake_gen=\", DO_FAKE_GEN,\n",
        "      \"| fake_train_infer=\", DO_FAKE_TRAIN_INFER,\n",
        "      \"| field_train_infer=\", DO_FIELD_TRAIN_INFER,\n",
        "      \"| batch=\", DO_BATCH_PROCESS)\n",
        "print(\"[config] TRAIN_TAR:\", TRAIN_TAR)\n",
        "print(\"[config] VAL_TAR  :\", VAL_TAR)\n",
        "print(\"[config] WEIGHTS  :\", WEIGHTS_DIR)\n",
        "print(\"[config] INFER_TMP_ROOT:\", INFER_TMP_ROOT)\n",
        "print(\"[config] SEQ_LEN:\", SEQ_LEN, \"| EPOCHS:\", EPOCHS, \"| FREEZE:\", BACKBONE_FREEZE_EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v5M2bD5LKOpp"
      },
      "outputs": [],
      "source": [
        "# === TAR staging (assume single top folder, no conditionals) ===\n",
        "import os, shutil, subprocess\n",
        "\n",
        "def stage_tar_to_root(tar_path: str, dest_root: str):\n",
        "    \"\"\"Extract `tar_path` into `dest_root`, assuming the tar was created from a single\n",
        "    top folder that contains the expected subfolders. We always:\n",
        "      • wipe dest_root\n",
        "      • extract to a temp dir\n",
        "      • move the single top folder's contents into dest_root\n",
        "    No structure probing; let errors surface if the tar is malformed.\n",
        "    \"\"\"\n",
        "    tmp = dest_root + \"__extract\"\n",
        "\n",
        "    # clean\n",
        "    if os.path.isdir(dest_root):\n",
        "        shutil.rmtree(dest_root, ignore_errors=True)\n",
        "    if os.path.isdir(tmp):\n",
        "        shutil.rmtree(tmp, ignore_errors=True)\n",
        "    os.makedirs(tmp, exist_ok=True)\n",
        "\n",
        "    # extract into tmp\n",
        "    subprocess.run([\"tar\", \"-xf\", tar_path, \"-C\", tmp], check=True)\n",
        "\n",
        "    # move contents of the single top folder into dest_root\n",
        "    top = os.path.join(tmp, os.listdir(tmp)[0])  # assume exactly one entry\n",
        "    os.makedirs(dest_root, exist_ok=True)\n",
        "    for name in os.listdir(top):\n",
        "        shutil.move(os.path.join(top, name), os.path.join(dest_root, name))\n",
        "\n",
        "    shutil.rmtree(tmp, ignore_errors=True)\n",
        "    print(f\"[stage] {os.path.basename(tar_path)} -> {dest_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A4G_xtenKiXf"
      },
      "outputs": [],
      "source": [
        "# === Priors: require precomputed (no creation) ===\n",
        "import os\n",
        "from config import (\n",
        "    SUB_RGB_850, SUB_AB_MASK_850, SUB_FB_MASK_850,\n",
        "    SUB_SIMPLE_POINT_170, SUB_SIMPLE_LINE_170,\n",
        "    SUB_LABEL_POINT_170, SUB_LABEL_LINE_170,\n",
        ")\n",
        "\n",
        "def require_priors_exist(root: str):\n",
        "    pt = os.path.join(root, SUB_SIMPLE_POINT_170)\n",
        "    ln = os.path.join(root, SUB_SIMPLE_LINE_170)\n",
        "    if not os.path.isdir(pt) or not os.listdir(pt):\n",
        "        raise FileNotFoundError(f\"[priors] missing or empty: {pt}\")\n",
        "    if not os.path.isdir(ln) or not os.listdir(ln):\n",
        "        raise FileNotFoundError(f\"[priors] missing or empty: {ln}\")\n",
        "    print(f\"[priors] OK at {root}\")\n",
        "\n",
        "def require_field_inputs_exist(root: str, need_labels: bool):\n",
        "    req = [SUB_RGB_850, SUB_AB_MASK_850, SUB_FB_MASK_850,\n",
        "           SUB_SIMPLE_POINT_170, SUB_SIMPLE_LINE_170]\n",
        "    if need_labels:\n",
        "        req += [SUB_LABEL_POINT_170, SUB_LABEL_LINE_170]\n",
        "    missing = [d for d in req if not os.path.isdir(os.path.join(root, d))]\n",
        "    if missing:\n",
        "        raise FileNotFoundError(f\"[field] missing subfolders under {root}: {missing}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "FcJ4QjycKmif",
        "outputId": "8272bbda-264f-4ccb-aeb4-c5f32db7365b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[run] Field train/infer from .tar (no priors generation)\n",
            "[stage] tmpvidroot3_simp.tar -> /content/_field_local/train\n",
            "[stage] tmpvidroot4_simp.tar -> /content/_field_local/val\n",
            "[priors] OK at /content/_field_local/train\n",
            "[priors] OK at /content/_field_local/val\n",
            "New https://pypi.org/project/ultralytics/8.3.218 available 😃 Update with 'pip install -U ultralytics'\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset '/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml' error ❌ '/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml' does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m             }:\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"yaml_file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/checks.py\u001b[0m in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{file}' does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: '/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml' does not exist",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2196160985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mrequire_priors_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_VAL_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTroph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fresh by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0m_train_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCAL_TRAIN_ROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCAL_VAL_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Troph_Min_5to_2_mod/troph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weights_dir, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_stage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_stage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m         \"\"\"\n\u001b[0;32m-> 2905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# avoid auto-downloading dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error ❌ {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset '/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml' error ❌ '/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml' does not exist"
          ]
        }
      ],
      "source": [
        "# === Orchestrator · Step-1 (YOLO-TCN) ===\n",
        "# Always writes inference to local tmp first, then syncs to Drive.\n",
        "\n",
        "import importlib\n",
        "import troph;     importlib.reload(troph)\n",
        "from troph import Troph\n",
        "import fake_data; importlib.reload(fake_data)\n",
        "\n",
        "def _train_and_predict(model: Troph, train_root: str, val_root: str):\n",
        "    # ---- Train ----\n",
        "    model.train(\n",
        "        train_root=train_root,\n",
        "        val_root=val_root,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        seq_len=SEQ_LEN,\n",
        "        label_dilate_radius=LABEL_DILATE_RADIUS,\n",
        "        backbone_freeze_epochs=BACKBONE_FREEZE_EPOCHS,  # ← consistent with config\n",
        "    )\n",
        "    model.save(WEIGHTS_DIR)\n",
        "\n",
        "    # ---- Infer (local tmp → then copy back) ----\n",
        "    summary = model.predict(\n",
        "        root=val_root,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        clear_outputs=True,\n",
        "        progress_every=PROGRESS_EVERY,\n",
        "        seq_len=SEQ_LEN,\n",
        "        tmp_root=INFER_TMP_ROOT,  # ← local-first writing handled inside troph.predict\n",
        "    )\n",
        "    print(summary)\n",
        "\n",
        "# — Run by toggles from the Config cell —\n",
        "if DO_FAKE_GEN:\n",
        "    print(\"[run] Generating FAKE train/val on disk…\")\n",
        "    fake_data.make_fake_trainval_folders(\n",
        "        FAKE_TRAIN_ROOT, FAKE_VAL_ROOT, n_train=256, n_val=64, seed=0\n",
        "    )\n",
        "    print(\"[run] Fake train/val ready.\")\n",
        "\n",
        "if DO_FAKE_TRAIN_INFER:\n",
        "    print(\"[run] Fake train/infer (sanity check)…\")\n",
        "    model = Troph()  # fresh\n",
        "    _train_and_predict(model, FAKE_TRAIN_ROOT, FAKE_VAL_ROOT)\n",
        "\n",
        "if DO_FIELD_TRAIN_INFER:\n",
        "    print(\"[run] Field train/infer from .tar (no priors generation)\")\n",
        "    stage_tar_to_root(TRAIN_TAR, LOCAL_TRAIN_ROOT)\n",
        "    stage_tar_to_root(VAL_TAR,   LOCAL_VAL_ROOT)\n",
        "\n",
        "    require_field_inputs_exist(LOCAL_TRAIN_ROOT, need_labels=True)\n",
        "    require_field_inputs_exist(LOCAL_VAL_ROOT,   need_labels=True)\n",
        "    require_priors_exist(LOCAL_TRAIN_ROOT)\n",
        "    require_priors_exist(LOCAL_VAL_ROOT)\n",
        "\n",
        "    model = Troph()  # fresh by default\n",
        "    _train_and_predict(model, LOCAL_TRAIN_ROOT, LOCAL_VAL_ROOT)\n",
        "\n",
        "if DO_BATCH_PROCESS:\n",
        "    print(\"[run] Batch processing reserved/off here.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3UkzkweIROA"
      },
      "source": [
        "Multiple datasets\n",
        "\n",
        "Report training loss too\n",
        "\n",
        "Data output test (visually and numerically) tar export\n",
        "\n",
        "The tag consistency problem\n",
        "\n",
        "Redesign loss/targets for sparse labels\n",
        "\n",
        "Make it so it only kills simple pred masks? ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIaXajYtIRDX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRasuBeAIQs5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7vucTrzM27W"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZiG1RyyM2kx"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7C7y85Ltvpv"
      },
      "source": [
        "Resume from here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FylexQC8-_hc"
      },
      "source": [
        "Resume from here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n44KWfd393LE"
      },
      "source": [
        "Now, dummy training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ8ZCyqZ93iD"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaZR6TpQ933L"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU9Ar19r9fL1"
      },
      "source": [
        "BELOW SETUP IS UNTESTED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sax5jtmb9irT"
      },
      "source": [
        "ACTUAL RUN STARTS HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUbtZrkD74FW"
      },
      "source": [
        "This takes considerably longer than YOLO inference, beware."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPxB6bvx25tQs5aznAmyH5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}